{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47d58d8-4f15-4657-8030-353f985f2c1f",
   "metadata": {},
   "source": [
    "# TensorFlow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd03c6d-0ae2-43d3-94c3-7ce42509a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Conv1D, AveragePooling1D, Concatenate\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8dc93-f036-4aae-8aeb-2cc172877ca3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28f1db-22f2-4c9c-bf7b-67586590fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e75d1-d62d-4923-b4b0-9404200bb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28,28]), # 多次元から一次元に変換\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax'),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb34ec-e23a-4743-a3c9-6c82ae1089ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86014ffc-667d-493e-9d9c-0b0b759455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b75a7b-23c3-4021-ad1b-7fda34181d3b",
   "metadata": {},
   "source": [
    "## コンパイル、Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c8ba4-0ac3-452d-b322-1d47b2f3f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62f1b6-40c7-4631-9eda-2a77f46923ec",
   "metadata": {},
   "source": [
    "### ファッションデータのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d4c7e-fd21-4674-a159-855d82308fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_data = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist_data.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6b4e9-75a6-4fc5-a2f0-c0b813d9d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "\t'T-shirt/top',\n",
    "\t'Trouser',\n",
    "\t'Pullover',\n",
    "\t'Dress',\n",
    "\t'Coat',\n",
    "\t'Sandal',\n",
    "\t'Shirt',\n",
    "\t'Sneaker',\n",
    "\t'Bag',\n",
    "\t'Ankle boot'\n",
    "]\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a604e2-0c49-4ba0-9859-bc231fc7b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259dceb5-0c5f-4970-86c1-6ae37ec707a2",
   "metadata": {},
   "source": [
    "### イメージ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64026ad-0598-434e-a7d2-cf9947bf2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "img = train_images[i,:,:]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f'label: {labels[train_labels[i]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bfd2e-899a-4176-bcdb-c5e8fb305025",
   "metadata": {},
   "source": [
    "### フィット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a23a4a-cce9-443b-a785-7642ace48774",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9402f-229c-4f3d-8194-9ab764d8a309",
   "metadata": {},
   "source": [
    "### トレーニングとテストのデータ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece54f0-f7c1-4454-9066-fa3f36e09ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532c60f-0108-477e-bbd7-35c7ef31955c",
   "metadata": {},
   "source": [
    "### トレーニングとテストを同時に渡す方法１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc876ff-bc15-4b6e-be6c-8d226de2dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(inputs, targets, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4ff9e-d73c-4694-a56a-0cfaa2f3d6a4",
   "metadata": {},
   "source": [
    "### トレーニングとテストを同時に渡す方法２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef757c-ccd3-4c2d-a274-1f8231ba38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f92c97-3fb7-42ab-9ecd-ace3de45d5a1",
   "metadata": {},
   "source": [
    "### ヒストリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e355d6-3241-4948-8e6b-26d59aabbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90b217-2e4a-4240-89a9-cd8350bc0a63",
   "metadata": {},
   "source": [
    "### プロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069b207-c8b7-4e87-8ce2-d0c24ddbeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = df.plot(y='loss', title='Loss vs. Epochs', legend=False)\n",
    "loss_plot.set(xlabel='Epochs', ylabel='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661b58b-141d-45e7-9087-2da0f4df22a9",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98cb15-6990-4f51-8b9b-341077317a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812bfe24-dfcf-4d4c-870e-361c229af1ba",
   "metadata": {},
   "source": [
    "### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe18d1-334d-4aef-b989-303d6b669922",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images[5][np.newaxis,...,np.newaxis])\n",
    "print(predictions)\n",
    "print(labels[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954a73b-e29c-4a70-84c4-cb2a70585060",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### weight初期値いろいろ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2882-1c0e-47b3-bd9b-59b2f1cb9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPooling1D \n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=16, kernel_size=3, input_shape=(128, 64), kernel_initializer='random_uniform', bias_initializer=\"zeros\", activation='relu'),\n",
    "    MaxPooling1D(pool_size=4),\n",
    "    Flatten(),\n",
    "    Dense(64, kernel_initializer='he_uniform', bias_initializer='ones', activation='relu'),\n",
    "])\n",
    "\n",
    "model.add(Dense(64, \n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "                bias_initializer=tf.keras.initializers.Constant(value=0.4), \n",
    "                activation='relu'),)\n",
    "\n",
    "model.add(Dense(8, \n",
    "                kernel_initializer=tf.keras.initializers.Orthogonal(gain=1.0, seed=None), \n",
    "                bias_initializer=tf.keras.initializers.Constant(value=0.4), \n",
    "                activation='relu'))\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "def my_init(shape, dtype=None):\n",
    "    return K.random_normal(shape, dtype=dtype)\n",
    "model.add(Dense(64, kernel_initializer=my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0d152-d89b-40c7-90dd-929b4e4acb3d",
   "metadata": {},
   "source": [
    "### アクティベーション関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab523c-c2f5-4d80-834b-7f8f44151b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([0.0,1.0,1.0])\n",
    "y_pred = tf.constant([0.4,0.8, 0.3])\n",
    "accuracy = K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "print(accuracy)\n",
    "\n",
    "y_true = tf.constant([[0.0,1.0],[1.0,0.0],[1.0,0.0],[0.0,1.0]])\n",
    "y_pred = tf.constant([[0.4,0.6], [0.3,0.7], [0.05,0.95],[0.33,0.67]])\n",
    "accuracy =K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc169b78-c573-47cb-9e16-b1127b3c77a8",
   "metadata": {},
   "source": [
    "### ワンホットエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2adf7d-182b-40f7-9a76-26de109aa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1, 5, 8, 10, 9, 1, 3, 4, 2, 6, 7]\n",
    "onehot = tf.keras.utils.to_categorical(labels)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc864173-7d26-4f4c-ac02-5d53a40e415e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 畳み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347c9de-4c87-423f-b4f4-23eb8478556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be52da-5190-425f-a0b3-9811961dc439",
   "metadata": {},
   "source": [
    "### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3976c7-3cfb-4073-b6c2-afecc31dac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 畳み込みレイヤー。フィルター数16、畳み込みカーネルの形状：(3,3)\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    # MaxPoolingレイヤー。プーリングウィンドウサイズ：(3,3)\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97615c-b930-440e-9a7a-9f56135f5c0c",
   "metadata": {},
   "source": [
    "### kernel_size, pool_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ee2fa-2bc6-49b1-99f2-d78c290c9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 次元のサイズが同じ場合は、kernel_size, pool_size で記述できる。\n",
    "    Conv2D(16, kernel_size=3, activation='relu', input_shape=(32, 32, 3)),\n",
    "    # 次元のサイズが同じ場合は、kernel_size, pool_size で記述できる。\n",
    "    MaxPooling2D(pool_size=3),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad61bd3-b96b-45bb-9569-fa3bf1255408",
   "metadata": {},
   "source": [
    "### パディング、ストライド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6c5ed-9102-4e3a-aa53-a47d8c128334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), padding='SAME', strides=2, activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338504e-fbbe-4ce8-8503-bf34d46a380c",
   "metadata": {},
   "source": [
    "### チャンネルの順序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e124b-9a20-43a0-98a4-6133352d7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # channels_lastの場合、(バッチサイズ, 高さ, 幅, チャンネル数)となる。\n",
    "    # channels_firstの場合、(バッチサイズ, チャンネル数, 高さ, 幅)となる。\n",
    "    Conv2D(16, (3, 3),activation='relu', input_shape=(32, 32, 3), data_format='channels_last'),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024941-7a0d-422d-8b77-59a11c5df86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5499c98-ebaf-496c-8c59-e5b24e18b3e2",
   "metadata": {},
   "source": [
    "# 正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122fe59-a028-426b-980d-cdeec406d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重み行列をカーネルともいう\n",
    "# L1\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          kernel_regularizer=tf.keras.regularizers.l1(0.005)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# L2\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# 両方、かつバイアス正則化\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          # 減衰係数：0.001\n",
    "          kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.001),\n",
    "          bias_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# L2正則化は安定性を高め、L1正則化は特徴選択の役割を果たす"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b15fba-adb9-404f-990f-4cacc3aae7c6",
   "metadata": {},
   "source": [
    "## ドロップアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77418d04-ba6c-4fb9-9ab1-926adba5c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    # 前後のレイヤーの接続は0.5の確率でゼロに設定される\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# トレーニング時はランダムにドロップアウトされる\n",
    "# fit() はトレーニングモード、evaluate(), predict() はテストモードで自動的に処理される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583ece7-ba31-463f-9623-bd50c9e8d5b7",
   "metadata": {},
   "source": [
    "## バッチ正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f87d51-9d0c-42a5-ae4d-768436a32f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=[train_data.shape[1],], activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea548f78-9813-4cfe-95f3-af5dd5807bc2",
   "metadata": {},
   "source": [
    "### バッチ正則化のカスタマイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e94238-c99e-4548-ba19-0dbdc0f2d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.BatchNormalization(\n",
    "    momentum=0.95, \n",
    "    epsilon=0.005,\n",
    "    axis = -1,\n",
    "    beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "    gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ffa4a-b9fb-4886-ae0e-8182ba34b03e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# コールバック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b2795-366a-493b-a0a8-c5a655804072",
   "metadata": {},
   "source": [
    "### トレーニング用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c9988-0423-4271-9e17-08b1a546aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class my_callback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print('train start')\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch %2 ==0:\n",
    "            print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {}: Average loss is {:7.2f}, mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, callbacks=[my_callbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf6704-6bc3-4b3d-8f2f-2c16a185d9df",
   "metadata": {},
   "source": [
    "### テスト用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b0a89-3ff4-47d2-bf0a-83f06f89abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testing_callback(Callback):\n",
    "    def on_test_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_test_end(self, epoch, logs=None):\n",
    "        pass\n",
    "\n",
    "model.evaluate(X_test, y_test, epochs=5, verbose=False, callbacks=[testing_callbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1af74a-a0ec-47a5-a592-1996a9e924a1",
   "metadata": {},
   "source": [
    "※predict用もあるが、同様なので省略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efac1d-c327-4077-a1ed-e50cd8f3ad28",
   "metadata": {},
   "source": [
    "### エポックの経過で学習率を変化させるコールバック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829c6c0-6b9e-43ca-a41d-619328e8184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = [\n",
    "    (4, 0.03), (7, 0.02), (11, 0.005), (15, 0.007)\n",
    "]\n",
    "\n",
    "def get_new_epoch_lr(epoch, lr):\n",
    "    # Checks to see if the input epoch is listed in the learning rate schedule \n",
    "    # and if so, returns index in lr_schedule\n",
    "    epoch_in_sched = [i for i in range(len(lr_schedule)) if lr_schedule[i][0]==int(epoch)]\n",
    "    if len(epoch_in_sched)>0:\n",
    "        # If it is, return the learning rate corresponding to the epoch\n",
    "        return lr_schedule[epoch_in_sched[0]][1]\n",
    "    else:\n",
    "        # Otherwise, return the existing learning rate\n",
    "        return lr\n",
    "\n",
    "class LRScheduler(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, new_lr):\n",
    "        super(LRScheduler, self).__init__()\n",
    "        # Add the new learning rate function to our callback\n",
    "        self.new_lr = new_lr\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Make sure that the optimizer we have chosen has a learning rate, and raise an error if not\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "              raise ValueError('Error: Optimizer does not have a learning rate.')\n",
    "                \n",
    "        # Get the current learning rate\n",
    "        curr_rate = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "        \n",
    "        # Call the auxillary function to get the scheduled learning rate for the current epoch\n",
    "        scheduled_rate = self.new_lr(epoch, curr_rate)\n",
    "\n",
    "        # Set the learning rate to the scheduled learning rate\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_rate)\n",
    "        print('Learning rate for epoch {} is {:7.3f}'.format(epoch, scheduled_rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112517f2-b5d7-4664-85bf-c368565f2ee0",
   "metadata": {},
   "source": [
    "### 早期打ち切り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80c365-def1-4c34-8dca-e83e5b11ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accurracy', patience=5, min_delta=0.01, mode='max')\n",
    "model.fit(x, y, epochs=100, validation_split=0.15, batch_size=64,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d78f7b-1c33-443f-a59c-8ebbf1bbc720",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateauによる学習率自動調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9719f22-60e4-4385-ae03-22330072eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ReduceLROnPlateau が学習率を自動的に調整する\n",
    "def get_callbacks():\n",
    "    early = EarlyStopping(patience=30, mode='min')\n",
    "    reduce = ReduceLROnPlateau(factor=0.2, patience=20)\n",
    "    return (early, reduce)\n",
    "\n",
    "early_stopping, learning_rate_reduction = get_callbacks()\n",
    "history = model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
    "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)\n",
    "\n",
    "print(learning_rate_reduction.patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a707ec7-e65a-42a9-b001-c1b1588772c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# セーブとロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d2b12-8c90-4eb1-af10-ce4ce667bb95",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250c586-ac3e-4705-9569-6ef277d93fe3",
   "metadata": {},
   "source": [
    "### ウェイトのみ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ede512-631b-46f9-9355-ad2d9a762bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(...)\n",
    "model.fit(X, y, epochs=10)\n",
    "\n",
    "model.save_weights('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad3d11-561b-4488-9dfb-6647e7001bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復元時、モデルを構築しなおす必要がある\n",
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(...)\n",
    "\n",
    "new_model = model.load_weights('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44eb76-9960-4421-87c7-313c4b9968d4",
   "metadata": {},
   "source": [
    "### すべて保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e79177-461e-44b5-8e8e-9ecb152c3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68204196-ae41-40cd-b6be-58a61101817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復元するときは、モデルを構築しなおす必要が無い\n",
    "new_model = load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b73cd1-c530-4452-bd01-cdfdabd351bc",
   "metadata": {},
   "source": [
    "## チェックポイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e27950-4a90-48a3-8244-ee3887372abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "checkpoint = ModelCheckpoint('my_model', save_weights_only=True)\n",
    "model.fit(X, y, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4d1cb-5e13-44be-a8d9-601ce55c2ea8",
   "metadata": {},
   "source": [
    "上記の場合、3つのファイルが生成される  \n",
    "checkopint  ・・・実際のモデルがどこに保存されているかを示すメタデータ  \n",
    "my_model.index  ・・・どのウェイトがどこに保存されているかを示す（分散環境で）  \n",
    "my_model.data-00000-of-00001  ・・・実際のウェイトが保存されている  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdbf44-558f-41b5-9f95-e114bf8f51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras H5形式で保存\n",
    "# ただし、一般的にはネイティブのTensorFlow形式を推奨\n",
    "checkpoint = ModelCheckpoint('keras_model.h5', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d905b9f-a5d8-4deb-b840-0966e7ff376f",
   "metadata": {},
   "source": [
    "keras_model.h5　　・・・HDF5ファイル（ウェイトのみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1f1c3-613c-4ef1-ad5f-9a6ebeb64cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ウェイト以外も保存する\n",
    "checkpoint = ModelCheckpoint('my_model', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8b7f5-a2cd-4cbf-a070-dd6b79d6ed96",
   "metadata": {},
   "source": [
    "この場合、サブディレクトリの下に次のファイルが生成される  \n",
    "my_model/assets/  ・・・グラフで使用されるファイルが保存されるサブディレクトリ  \n",
    "my_model/saved_model.pb  ・・・TensorFlowグラフ自体（モデルアーキテクチャ）を保存  \n",
    "my_model/variables/variables.data-00000-of-00001  ・・・ウェイト  \n",
    "my_model/variables/variables.index  ・・・ウェイトの場所  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c4bdc-d78b-4889-b004-81910a93bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5でウェイト以外も\n",
    "checkpoint = ModelCheckpoint('keras_model.h5', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790dae6-b51f-4b40-bc2f-7a5dd7fd05e7",
   "metadata": {},
   "source": [
    "keras_model.h5　　・・・HDF5ファイル（アーキテクチャ全体が含まれる）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8505af-f15b-4146-8016-0c8fc5da3009",
   "metadata": {},
   "source": [
    "### チェックポイントの復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a2ecf-5006-4488-b04b-41fbc56c1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルは再構築しておく必要がある\n",
    "model.load_weights('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c574f9-ce17-43e8-874f-9a0353a0d9c5",
   "metadata": {},
   "source": [
    "### チェックポイントの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a7b32-bb66-46ac-8e26-ab0e08c9e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存頻度（デフォルトはエポック毎）\n",
    "# 最後に重みを保存してからモデルが見たサンプル数で指定\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model', save_weights_only=True,\n",
    "                            save_freq=1000)\n",
    "\n",
    "# パフォーマンス測定基準に従ってのみ保存\n",
    "# 下記の場合、検証損失がトレーニング実行で最高の値になった場合のみ保存する\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model', save_weights_only=True,\n",
    "                            save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# ログディクショナリにあるどんなキーでもフォーマット可能（上書きを防げる）\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model.{epoch}.{batch}',\n",
    "                             save_weights_only=True, save_freq=1000)\n",
    "checkpoint = ModelCheckpoint('training_run_2/my_model.{epoch}-{val_loss.4f}',\n",
    "                             save_weights_only=True, save_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b42a5a-e237-4a2b-94fd-0a62f41d9cdf",
   "metadata": {},
   "source": [
    "## モデルアーキテクチャのみ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92100f-12b5-4784-b9ad-32dd433f2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=32, input_shape=(32, 32, 3), activation='relu', name='dense_1'),\n",
    "    Dense(units=10, activation='softmax', name='dense_2')\n",
    "])\n",
    "\n",
    "config_dict = model.get_config()\n",
    "print(config_dict)\n",
    "\n",
    "model_same_config = tf.keras.Sequential.from_config(config_dict)\n",
    "\n",
    "# アーキテクチャは同じ\n",
    "print('Same config:', model.get_config() == model_same_config.get_config())\n",
    "# ウェイトは異なる\n",
    "print('Same value for first weight matrix:', np.allclose(model.weights[0].numpy(), model_same_config.weights[0].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe3b20-b241-4270-ae23-7d1decdfda2e",
   "metadata": {},
   "source": [
    "## 保存形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223190d-24fc-4e8e-9b55-2b31b1d8cb5a",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34491930-cda8-4322-9d53-3e10a17732b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSONで保存。（ウェイトは含まれない）\n",
    "json_string = model.to_json()\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(json_string, f)\n",
    "del json_string\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    json_string = json.load(f)\n",
    "model_same_config = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b98a69-8882-42b2-b547-02505f7d05e6",
   "metadata": {},
   "source": [
    "### YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296795bb-a2da-4ac3-bb84-1148d6935522",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa872801-2357-400d-99ad-3f60a391056c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 事前学習されたKerasモデルのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b33b6-3842-4734-a711-23c0f9fd2f53",
   "metadata": {},
   "source": [
    "## Keras Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7410feb-8466-4ae6-a44a-39fa807787f6",
   "metadata": {},
   "source": [
    "https://keras.io/ja/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235c859-fe60-4b20-8c01-ff6485e6a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# imagenetデータセットで学習したモデルが、\n",
    "# ~/.keras/models にウェイト付きでダウンロードされる\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# 全結合層を含まずにダウンロードされる\n",
    "# 転移学習アプリケーションなどに使用できるヘッドモデル\n",
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0475a41-d47e-4d7d-a70a-71f5e86baba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# ResNet50に必要なサイズである224x224に、自動的に変換される\n",
    "img_input = image.load_img('my_picture.jpg', target_size=(224, 224))\n",
    "img_input = image.img_to_array(img_input)\n",
    "img_input = preprocess_input(img_input[np.newaxis, ...])\n",
    "\n",
    "preds = model.predict(img_input)\n",
    "decoded_predictions = decode_predictions(preds, top=3)[0]\n",
    "# List of (class, description, probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735714a6-0944-4571-8ce9-6ace4da07d8e",
   "metadata": {},
   "source": [
    "## TensorFlow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e66db-7cf9-42c8-9dd2-eca3263c052a",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/hub?hl=ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ea34e-50bd-47bc-becf-e7fa5047fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "時間かかるので不用意に実行しない。\n",
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\n",
    "model = Sequential([hub.KerasLayer(module_url)])\n",
    "model.build(input_shape=[None, 160, 160, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c27d4f-f367-4020-9a61-945c40423c1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 関数API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2410c5c-8953-41ec-b5e7-7057361f6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "# 損失関数はoutputsと同じ順で２つ指定する\n",
    "# binary_crossentropy + 0.4 * mse が最終的な損失になる\n",
    "model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 0.4], metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train, X_aux], [y_train, y_aux], validation_split=0.2, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b30504-616b-442a-a634-dfe0cabb2abd",
   "metadata": {},
   "source": [
    "### モデルを視覚化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904cf0b-75d1-4f62-8b5b-e2056bba39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "plot_model(model, 'multi_input_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb91ee1-364e-4879-a7c3-cf504096c84b",
   "metadata": {},
   "source": [
    "### 変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68096c2b-9fdb-47e3-9cfe-f62c90c46a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = tf.Variable([-1, 2], dtype=tf.float32) # 変数の初期値\n",
    "print(my_var)\n",
    "my_var.assign([3.5, -1.])\n",
    "print(my_var)\n",
    "\n",
    "x = my_var.numpy() # numpyに変換\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb9dda-5863-485f-b6f9-1efb3fe41c1f",
   "metadata": {},
   "source": [
    "### テンソル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dec84-762c-461f-80da-24fe44c28e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones(shape=(2, 1))\n",
    "print(x)\n",
    "y = tf.zeros(shape=(2, 1))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db557460-0e61-440d-b4dc-a137ada0cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= tf.constant(np.arange(24), shape=(3, 2, 4))\n",
    "print(t)\n",
    "t1 = tf.expand_dims(t, 0)\n",
    "print(t1)\n",
    "t2 = tf.expand_dims(t, 1)\n",
    "print(t2)\n",
    "t3 = tf.expand_dims(t, 2)\n",
    "print(t3)\n",
    "\n",
    "print(tf.squeeze(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6ee8e-2c53-45fa-9cc2-8bfb6807a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 2.0], [0.0, 1.0]])\n",
    "\n",
    "cd_mutmul = tf.matmul(c, d) # 行列の掛け算\n",
    "print(cd_mutmul)\n",
    "\n",
    "cd_x = c * d # 各要素の掛け算\n",
    "print(cd_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970b4dd-6125-4848-9d08-369983f4d4a7",
   "metadata": {},
   "source": [
    "### レイヤー変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b02225-a2a8-4a65-81f4-b7b2341ef75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu', name='conv1d_layer')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "model.layers # 全レイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afc99e-34f8-469e-b451-085cbf9f701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].weights) # 特定のレイヤーのウェイト（TensorFlow変数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681edad-28d6-4b3a-a799-8d0ca71f9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].get_weights()) # 単なる数値として取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd0d89-f0a9-4545-aa63-7f09de1c6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].kernel) # カーネル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbe474-95d0-44f6-b5b0-c6eb95cbbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].bias) # バイアス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2285f4-bf99-42aa-a90e-1bd61b4d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_layer('conv1d_layer').bias) # レイヤー名で参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "154458ae-7ade-499f-8101-1c254d1dc564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 1), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'input_7'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 16), dtype=tf.float32, name=None), name='conv1d_layer/Relu:0', description=\"created by layer 'conv1d_layer'\")\n"
     ]
    }
   ],
   "source": [
    "# 入出力テンソル\n",
    "print(model.get_layer('conv1d_layer').input)\n",
    "print(model.get_layer('conv1d_layer').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cf30910-36ce-4d9e-85d8-7b373cace2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu', name='conv1d_layer')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten(name='flatten_layer')(h)\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "flatten_output = model.get_layer('flatten_layer').output\n",
    "\n",
    "model2 = Model(inputs=model.input, outputs=flatten_output)\n",
    "\n",
    "# 最後のDense層だけ入れ替えた形\n",
    "model3  = Sequential([\n",
    "    model2,\n",
    "    Dense(10, activation='softmax', name='new_dense_layer')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc2c03-98ef-4efc-aee7-a63f39e30db2",
   "metadata": {},
   "source": [
    "### フリーズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02024ed-58bb-469a-b517-04556d3120fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# レイヤーをフリーズ\n",
    "model.get_layer('conv2d_layer').trainable = False\n",
    "model.compile(...)\n",
    "\n",
    "# モデルをフリーズ\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562a7be-8240-42b8-b62e-f1ba4f8371f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# データセット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5278a-7246-4931-a4ff-4e6342558087",
   "metadata": {},
   "source": [
    "### ランダム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85a193b-e9cf-4810-ae19-cac9acb5ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(4,), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random.uniform([256, 4], minval=1, maxval=10, dtype=tf.int32),\n",
    "     tf.random.normal([256]))\n",
    ")\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fae63-d8c2-4c27-bad4-15c96cd641ba",
   "metadata": {},
   "source": [
    "## CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426d39ac-669f-4a56-9eb3-17c8cbad34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 73s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2bc913-96a9-4a85-89b1-948fb3f2bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16885e62-d7fe-462b-b705-7cc946e62766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[100])\n",
    "print(y_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983546ca-4d00-4782-bb42-b3fff3836552",
   "metadata": {},
   "source": [
    "## ジェネレーター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c537a34-3b20-495e-930f-951cc5bf2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "# datagen は yield でイテレーションのデータを返すデータセット\n",
    "# エポック当たりのステップ数を指定する必要がある\n",
    "model.fit_generator(datagen, steps_per_epoch=1000, epochs=10)\n",
    "\n",
    "model.evaluate_generator(datagen_eval, staps=100)\n",
    "\n",
    "model.predict_generator(datagen_test, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25763b-eab9-491c-a063-085f340c78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator(width_shift_range=0.2, horizontal_flip=True)\n",
    "dataset = tf.data.Dataset.from_generator(img_datagen.flow, args=[x_train, y_train],\n",
    "                                        output_types=(tf.float32, tf.int32),\n",
    "                                        output_shapes=([32, 32, 32, 3], [32, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f1f99-3b17-4597-9345-fd88e127b697",
   "metadata": {},
   "source": [
    "## オーグメンテーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cbf5d-3491-4c70-967f-204120a51868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "image_data_gen = ImageDataGenerator(rescale=1/255., # 範囲を0から1の間にする\n",
    "                                    horizontal_flip=True, # 上下反転して複製\n",
    "                                    height_shift_range=0.1, # 画像の高さの20％の幅でランダムに上下シフト\n",
    "                                    fill_mode='nearest', # 足りないピクセルの埋め方（デフォルト）\n",
    "                                    featurewise_center=True # データセット全体における個々の特徴の平均が0になるよう標準化\n",
    "                                   )\n",
    "\n",
    "image_data_gen.fit(x_train)\n",
    "\n",
    "train_datagen = image_data_gen.flow(x_train, y_train, batch_size=16)\n",
    "\n",
    "model.fit_generator(train_datagen, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc5298-9a26-4775-989b-52af3d330307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monochrome(x):\n",
    "    def func_bv(a):\n",
    "        average_colour = np.mean(a)\n",
    "        return [average_colour, average_colour, average_colour]\n",
    "    x = np.apply_along_axis(func_bv, -1, x)\n",
    "    return x\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "                                    preprocessing_function=monochrome,\n",
    "                                    rotation_range=180,\n",
    "                                    rescale=1/255.\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2654cba-ab30-478d-ba55-eca7c3d8279a",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f40ecc-af38-45ad-9b20-c87df88cfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, labels):\n",
    "    return tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "\n",
    "train_dataset = create_dataset(train_data, train_labels)\n",
    "test_dataset = create_dataset(test_data, test_labels)\n",
    "\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c760b-ef93-48d0-adee-7881868fe696",
   "metadata": {},
   "source": [
    "## フィルター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa345ca6-e3cc-45ef-81d7-941e7790f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_classes(dataset, classes):\n",
    "    def filter_func(image, label):\n",
    "        return tf.math.reduce_any(tf.equal(label, classes))\n",
    "    return  dataset.filter(filter_func)\n",
    "\n",
    "cifar_classes = [0, 29, 99] # Your datasets should contain only classes in this list\n",
    "train_dataset = filter_classes(train_dataset, cifar_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f5aad-d7a6-4d16-a932-088b7c8178ef",
   "metadata": {},
   "source": [
    "## ラベルのマッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481ab97-0d3c-4208-8422-b9696a72b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルをワンホットエンコーディングに変換している\n",
    "def map_labels(dataset):\n",
    "    def one_hot_encode_label(image, label):\n",
    "        num_classes = 3  # クラス数\n",
    "        one_hot_label = tf.one_hot(label, num_classes, on_value=1.0, off_value=0.0)\n",
    "        return image, one_hot_label\n",
    "\n",
    "    return dataset.map(one_hot_encode_label)\n",
    "\n",
    "train_dataset = map_labels(train_dataset)\n",
    "test_dataset = map_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa64c4-b4c9-4f15-8f5b-91e31b4a769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルとエンコーディングの順序を保証する形\n",
    "def map_labels2(dataset):\n",
    "    def one_hot_encode_label(image, label):\n",
    "        encoded_label = tf.zeros(3)\n",
    "        if label == 0:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[0]], [1.0])\n",
    "        elif label == 29:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[1]], [1.0])\n",
    "        elif label == 99:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[2]], [1.0])\n",
    "        return image, encoded_label\n",
    "\n",
    "    return dataset.map(one_hot_encode_label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f06f1-6ee5-406e-a80f-a59fde5841f5",
   "metadata": {},
   "source": [
    "## 時系列ジェネレーター"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee8ce2-8e6c-4d06-81d1-0dcbf0e13d9e",
   "metadata": {},
   "source": [
    "### 動作例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23d34b1-6e56-4fc6-833a-6ecce3cf001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[ 10  20  30  40  50  60  70  80  90 100]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dummy_data = np.arange(1, 11, 1)\n",
    "dummy_targets = np.arange(10, 110, 10)\n",
    "print(dummy_data)\n",
    "print(dummy_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc823f3-78a8-40cb-a2e2-dafcf1d6a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 1\n",
      "\n",
      "Data:\n",
      "[[1 2 3 4]\n",
      " [2 3 4 5]\n",
      " [3 4 5 6]\n",
      " [4 5 6 7]\n",
      " [5 6 7 8]\n",
      " [6 7 8 9]]\n",
      "Targets:\n",
      "[ 50  60  70  80  90 100]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, 4)\n",
    "\n",
    "print('Length:', len(timeseries_gen))\n",
    "inputs, outputs = timeseries_gen[0]\n",
    "print(\"\\nData:\")\n",
    "print(inputs)\n",
    "print(\"Targets:\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81323a44-b0cb-4ae3-acfd-a9e976706d64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93546cea-4bb8-4a00-b835-c8bccfa1808b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [2, 3, 4]]),\n",
       " array([40, 50]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, batch_size=2)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "next(timeseries_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0917c2-07fb-4cff-9a45-df5db93d051d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ストライド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f771bb3-a8ca-4304-9c75-c53f4fd023e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[1, 2, 3]]), array([40]))\n",
      "(array([[3, 4, 5]]), array([60]))\n",
      "(array([[5, 6, 7]]), array([80]))\n",
      "(array([[7, 8, 9]]), array([100]))\n"
     ]
    }
   ],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, stride=2, batch_size=1)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(next(timeseries_iterator))\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae293643-e73e-42fd-80b7-be2b41582187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### リバース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a50b96-2b63-4071-962a-18e952f36b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[3, 2, 1]]), array([40]))\n",
      "(array([[4, 3, 2]]), array([50]))\n",
      "(array([[5, 4, 3]]), array([60]))\n",
      "(array([[6, 5, 4]]), array([70]))\n",
      "(array([[7, 6, 5]]), array([80]))\n",
      "(array([[8, 7, 6]]), array([90]))\n",
      "(array([[9, 8, 7]]), array([100]))\n"
     ]
    }
   ],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, stride=1, batch_size=1, reverse=True)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(next(timeseries_iterator))\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae6044-8e56-48aa-8890-e981df328a61",
   "metadata": {},
   "source": [
    "### オーディオ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e736e1c-623a-40f9-97e6-d7f0eaf464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "rate, song = read(\"data/055 - Angels In Amplifiers - I'm Alright/mixture.wav\")\n",
    "print(\"rate:\", rate)\n",
    "song = np.array(song)\n",
    "print(\"song.shape:\", song.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389575f6-12ad-4700-ada5-c2341fb47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_gen = TimeseriesGenerator(song, targets=song, length=200000, stride=200000, batch_size=1)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "for i in range(3):\n",
    "    sample, target = next(timeseries_iterator)\n",
    "    write('example.wav', rate, sample[0])\n",
    "    print('Sample {}'.format(i+1))\n",
    "    ipd.display(ipd.Audio(\"example.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf307933-a419-4904-8b8d-7aa9ce6c14f1",
   "metadata": {},
   "source": [
    "# シーケンシャルデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32d06d-5fbb-45af-b9e0-39d8aab7e471",
   "metadata": {},
   "source": [
    "## パディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f893a-8960-4edd-bbc2-18d5dc9de8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "test_input = [\n",
    "    [4, 12, 33, 18],\n",
    "    [63, 23, 54, 30, 19, 3],\n",
    "    [43, 37, 11, 33, 15]\n",
    "]\n",
    "\n",
    "preprocessed_data = pad_sequences(test_input, padding='pre') # リストのリストを渡す\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbe09b-f4ed-4ae5-abd9-2e8246fee4d9",
   "metadata": {},
   "source": [
    "[[ 0  0  4 12 33 18]  \n",
    " [63 23 54 30 19  3]  \n",
    " [ 0 43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980a59b-4d5a-45ee-95fd-870082142152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大長指定（前を切り捨て）\n",
    "preprocessed_data = pad_sequences(test_input, padding='post', maxlen=5)\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121237a-0e72-475a-b6f7-0aa1a84c3250",
   "metadata": {},
   "source": [
    "[[ 4 12 33 18  0]  \n",
    " [23 54 30 19  3]  \n",
    " [43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed6e20-3448-4b0a-a659-2848f2df70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大長指定（後を切り捨て）\n",
    "preprocessed_data = pad_sequences(test_input, padding='post', maxlen=5, truncating='post')\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab81392-88de-4f38-b53c-6682a95cd9b3",
   "metadata": {},
   "source": [
    "[[ 4 12 33 18  0]  \n",
    " [63 23 54 30 19]  \n",
    " [43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ab16b-d9f2-4e8f-b0c1-24a298e1b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パディング値を指定\n",
    "preprocessed_data = pad_sequences(test_input, value=-1)\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece14e4-724e-4fe2-a7e9-9e0a68ca1a0d",
   "metadata": {},
   "source": [
    "[[-1 -1  4 12 33 18]  \n",
    " [63 23 54 30 19  3]  \n",
    " [-1 43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d7247-9195-45da-bad1-71960ff728e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Masking\n",
    "import numpy as np\n",
    "\n",
    "test_input = [\n",
    "    [4, 12, 33, 18],\n",
    "    [63, 23, 54, 30, 19, 3],\n",
    "    [43, 37, 11, 33, 15]\n",
    "]\n",
    "\n",
    "preprocessed_data = pad_sequences(test_input, padding='post')\n",
    "\n",
    "masking_layer = Masking(mask_value=0)\n",
    "preprocessed_data = preprocessed_data[..., np.newaxis] # (batch_size, seq_length, features)\n",
    "masked_input = masking_layer(preprocessed_data)\n",
    "print(masked_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645ecc4-4e6d-419e-9dfa-eb65f68dc68f",
   "metadata": {},
   "source": [
    "[[[ 4]\n",
    "  [12]\n",
    "  [33]\n",
    "  [18]\n",
    "  [ 0]\n",
    "  [ 0]],  \n",
    " [[63]\n",
    "  [23]\n",
    "  [54]\n",
    "  [30]\n",
    "  [19]\n",
    "  [ 3]],  \n",
    " [[43]\n",
    "  [37]\n",
    "  [11]\n",
    "  [33]\n",
    "  [15]\n",
    "  [ 0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be180e-56fb-4149-8ca4-a5504c50bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_input._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1c69d-b245-421d-88c3-2f6233b5c8e7",
   "metadata": {},
   "source": [
    "<tf.Tensor: shape=(3, 6), dtype=bool, numpy=  \n",
    "array([[ True,  True,  True,  True, False, False],  \n",
    "       [ True,  True,  True,  True,  True,  True],  \n",
    "       [ True,  True,  True,  True,  True, False]])>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c2eca-2a5b-4de1-8969-977539fe8f9a",
   "metadata": {},
   "source": [
    "## 埋め込み層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5c8fd-622e-46a2-9488-4e3f41b86bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "# 1000個の異なるトークンを32次元の浮動小数点ベクトルに埋め込む\n",
    "embedding_layer = Embedding(1000, 32, input_length=64)\n",
    "# 16個のシーケンスで各シーケンスは64個の整数で構成。値は0から999までの範囲。\n",
    "test_input = np.random.randint(1000, size=(16, 64))\n",
    "\n",
    "# 埋め込み層をテストデータに適用し、元の整数シーケンスを32次元浮動小数点ベクトルに変換\n",
    "embedded_inputs = embedding_layer(test_input) # (16, 64, 32)\n",
    "print(embedded_inputs)\n",
    "#embedded_inputs._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b150802-ba40-4f07-b03c-4d7f2816d7ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 再帰ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de84d29-4ba1-4846-9f7f-4d1b8c8c3cd2",
   "metadata": {},
   "source": [
    "### シンプルRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f50c46-96c6-4c1f-8eb9-00effa44f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長64、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32, input_length=64), # (None, 64, 32)\n",
    "    SimpleRNN(64, activation='tanh'),     # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18d883-bd8f-45b3-9332-827ea43adde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意のシーケンス長\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    SimpleRNN(64, activation='tanh'),     # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855f8a7-a812-48b7-980d-b299d8b7c3fb",
   "metadata": {},
   "source": [
    "### LSTM（長・短期記憶）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c09988-28bb-410e-a4b3-9ee74a537ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    LSTM(64, activation='tanh'),          # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b335e-52f9-4420-863e-9740db0134f8",
   "metadata": {},
   "source": [
    "### GRU（ゲート付き反復単位）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da681912-fecf-4c2e-9f42-52d3a8e56c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    GRU(64, activation='tanh'),           # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607fe05-9909-48b5-901a-b6fcb37971f6",
   "metadata": {},
   "source": [
    "## スタック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d468b-5bfd-4698-832c-7c78071ce133",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff3c6130-c2ce-47fd-bb08-b396f8ad54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Input\n",
    "\n",
    "inputs = Input(shape=(None, 10))            # (None, None, 10)\n",
    "h = Masking(mask_value=0)(inputs)           # (None, None, 10)\n",
    "# タイムステップごとに出力を返す\n",
    "h = LSTM(32, return_sequences=True)(h)      # (None, None, 32) \n",
    "h = LSTM(64)(h)                             # (None, 64)\n",
    "outputs = Dense(5, activation='softmax')(h) # (None, 5)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b266d40-124a-4c14-b7c8-71f4a7edc748",
   "metadata": {},
   "source": [
    "### 双方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ce63918-514f-40d3-a651-a72186fccf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Input, Bidirectional\n",
    "\n",
    "# 過去だけでなく未来のコンテキストも考慮したいとき、Bidirectionalが使える\n",
    "inputs = Input(shape=(None, 10))                          # (None, None, 10)\n",
    "h = Masking(mask_value=0)(inputs)                          # (None, None, 10)\n",
    "h = Bidirectional(LSTM(32, return_sequences=True))(h)      # (None, None, 64) \n",
    "h = Bidirectional(LSTM(64))(h)                             # (None, 128) \n",
    "outputs = Dense(5, activation='softmax')(h)                # (None, 5)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931f723-b791-4f16-a1ee-57d7cf5c1c7c",
   "metadata": {},
   "source": [
    "# カスタムモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0206cca-b39d-4250-a180-613650415025",
   "metadata": {},
   "source": [
    "## モデルサブクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666ffbae-89bb-48b7-9f6c-f289a006b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            multiple                  176       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 346 (1.35 KB)\n",
      "Trainable params: 346 (1.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, num_classes, **kargs):\n",
    "        super(MyModel, self).__init__(**kargs)\n",
    "        self.dense1 = Dense(16, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense2 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.dense1(inputs)\n",
    "        h = self.dropout(h, training=training)\n",
    "        return self.dense2(h)\n",
    "\n",
    "my_model = MyModel(10, name='my_model')\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6d3d12-c0eb-40de-bade-42a564ca9e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            multiple                  704       \n",
      "                                                                 \n",
      " dense_25 (Dense)            multiple                  110       \n",
      "                                                                 \n",
      " dense_26 (Dense)            multiple                  55        \n",
      "                                                                 \n",
      " softmax_5 (Softmax)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 869 (3.39 KB)\n",
      "Trainable params: 869 (3.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(10)\n",
    "        self.dense3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        y1 = self.dense2(inputs)\n",
    "        y2 = self.dense3(y1)\n",
    "        concat = concatenate([x,y2])\n",
    "        return self.softmax(concat)\n",
    "\n",
    "my_model = MyModel()\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dad364-41ba-47dc-807d-2d5e049d1dde",
   "metadata": {},
   "source": [
    "## カスタムレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92cfa4cf-7d2a-4730-a21d-fb7e27058ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
      "array([[ 0.04816338, -0.00684367],\n",
      "       [ 0.04727383,  0.03168861],\n",
      "       [-0.02809448,  0.03711691]], dtype=float32)>]\n",
      "tf.Tensor([[0.06734273 0.06196186]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class LinearMap(Layer):\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(LinearMap, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units)))\n",
    " \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "\n",
    "linear_layer = LinearMap(3, 2)\n",
    "print(linear_layer.weights)\n",
    "\n",
    "inputs = tf.ones((1, 3))\n",
    "print(linear_layer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aec6993-a4cb-4a33-8ed0-f12265eca007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            multiple                  704       \n",
      "                                                                 \n",
      " linear_map_4 (LinearMap)    multiple                  768       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1472 (5.75 KB)\n",
      "Trainable params: 1472 (5.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# カスタムレイヤーを使ったカスタムモデル\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, hidden_units, outputs, **kargs):\n",
    "        super(MyModel, self).__init__(**kargs)\n",
    "        self.dense1 = Dense(hidden_units, activation='sigmoid')\n",
    "        self.linear = LinearMap(hidden_units, outputs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h = self.dense1(inputs)\n",
    "        return self.linear(h)\n",
    "\n",
    "my_model = MyModel(64, 12, name='my_model')\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430fa28-34d5-4b44-8d42-89dc2da8040b",
   "metadata": {},
   "source": [
    "## 自動微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9d0d3d7-4cc9-4784-81e3-95d3e41ea579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x) # 以降のxに対する操作が記録される\n",
    "    y = x**2\n",
    "    grad = tape.gradient(y, x) # xに関して微分したいテンソルを渡し、結果をテンソルgradに格納\n",
    "\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a72dadba-8564-4e88-9fa5-dada27e9807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.13673721, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_sum(x**2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy = tape.gradient(z, y)\n",
    "\n",
    "print(dz_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a0c702-e002-45e4-8efe-ab6bdc2f7d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.13673721, shape=(), dtype=float32)\n",
      "tf.Tensor([0.         0.27347443 0.54694885 0.82042325], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_sum(x**2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy, dz_dx = tape.gradient(z, [y, x])\n",
    "\n",
    "print(dz_dy)\n",
    "print(dz_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac4bfe-1837-47bb-b080-fbdab146338d",
   "metadata": {},
   "source": [
    "## カスタムトレーニングループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394763d-d73c-464e-a462-0c222cb1077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "my_model = MyModel()\n",
    "loss = MeanSquaredError()\n",
    "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_losses = []\n",
    "    \n",
    "    for inputs, outputs in training_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # tape.watch() を実行していない理由は、\n",
    "            # TensorFlow変数オブジェクトを使用する計算がコンテキストによって自動的に記録されるから。\n",
    "            current_loss = loss(my_model(inputs), outputs)\n",
    "            grads = tape.gradient(current_loss, my_model.trainable_variables)\n",
    "    \n",
    "        batch_losses.append(current_loss)\n",
    "        optimizer.apply_gradients(zip(grads, my_model.trainable_variables))\n",
    "\n",
    "    epoch_losses.append(np.mean(batch_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3dcca-1838-4524-b217-5178d2f5c1ae",
   "metadata": {},
   "source": [
    "## tf.function デコレータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bc2cf-e364-45d3-9c7b-ec8514dc2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "my_model = MyModel()\n",
    "loss = MeanSquaredError()\n",
    "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "\n",
    "# この関数からグラフが作成されるので、多くの場合、はるかに高速に実行される\n",
    "@tf.function\n",
    "def get_loss_and_graph(inputs, outputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(my_model(inputs), outputs)\n",
    "        grads = tape.gradient(current_loss, my_model.trainable_variables)\n",
    "    return current_loss, grads\n",
    "\n",
    "current_loss, grads = get_loss_and_grads(inputs, outputs)\n",
    "optimizer.apply_gradients(zip(grads, my_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22d2f1-3401-4965-a90b-a48b6d4cc9e6",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16922e0e-8ef4-4db5-b72f-3f91fef920f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape=(28, 28, 1)\n",
    "input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d01e9d9-2aa7-4d96-a6e4-a143e77ef08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
