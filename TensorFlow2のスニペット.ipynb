{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c47d58d8-4f15-4657-8030-353f985f2c1f",
   "metadata": {},
   "source": [
    "# TensorFlow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd03c6d-0ae2-43d3-94c3-7ce42509a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Input, Conv1D, AveragePooling1D, Concatenate\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8dc93-f036-4aae-8aeb-2cc172877ca3",
   "metadata": {},
   "source": [
    "# 基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c28f1db-22f2-4c9c-bf7b-67586590fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29e75d1-d62d-4923-b4b0-9404200bb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28,28]), # 多次元から一次元に変換\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax'),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dbb34ec-e23a-4743-a3c9-6c82ae1089ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                12560     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13002 (50.79 KB)\n",
      "Trainable params: 13002 (50.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86014ffc-667d-493e-9d9c-0b0b759455a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b75a7b-23c3-4021-ad1b-7fda34181d3b",
   "metadata": {},
   "source": [
    "## コンパイル、Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641c8ba4-0ac3-452d-b322-1d47b2f3f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D((3,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy(), tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62f1b6-40c7-4631-9eda-2a77f46923ec",
   "metadata": {},
   "source": [
    "### ファッションデータのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c6d4c7e-fd21-4674-a159-855d82308fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist_data = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist_data.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47a6b4e9-75a6-4fc5-a2f0-c0b813d9d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "\t'T-shirt/top',\n",
    "\t'Trouser',\n",
    "\t'Pullover',\n",
    "\t'Dress',\n",
    "\t'Coat',\n",
    "\t'Sandal',\n",
    "\t'Shirt',\n",
    "\t'Sneaker',\n",
    "\t'Bag',\n",
    "\t'Ankle boot'\n",
    "]\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a604e2-0c49-4ba0-9859-bc231fc7b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259dceb5-0c5f-4970-86c1-6ae37ec707a2",
   "metadata": {},
   "source": [
    "### イメージ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64026ad-0598-434e-a7d2-cf9947bf2048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "img = train_images[i,:,:]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "print(f'label: {labels[train_labels[i]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bfd2e-899a-4176-bcdb-c5e8fb305025",
   "metadata": {},
   "source": [
    "### フィット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a23a4a-cce9-443b-a785-7642ace48774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 3s 10ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.7948 - mean_absolute_error: 4.4200\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3777 - sparse_categorical_accuracy: 0.8674 - mean_absolute_error: 4.4200\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3410 - sparse_categorical_accuracy: 0.8804 - mean_absolute_error: 4.4200\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3238 - sparse_categorical_accuracy: 0.8861 - mean_absolute_error: 4.4200\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 2s 10ms/step - loss: 0.3081 - sparse_categorical_accuracy: 0.8893 - mean_absolute_error: 4.4200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9402f-229c-4f3d-8194-9ab764d8a309",
   "metadata": {},
   "source": [
    "### トレーニングとテストのデータ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece54f0-f7c1-4454-9066-fa3f36e09ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532c60f-0108-477e-bbd7-35c7ef31955c",
   "metadata": {},
   "source": [
    "### トレーニングとテストを同時に渡す方法１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc876ff-bc15-4b6e-be6c-8d226de2dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(inputs, targets, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4ff9e-d73c-4694-a56a-0cfaa2f3d6a4",
   "metadata": {},
   "source": [
    "### トレーニングとテストを同時に渡す方法２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bef757c-ccd3-4c2d-a274-1f8231ba38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels,\n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f92c97-3fb7-42ab-9ecd-ace3de45d5a1",
   "metadata": {},
   "source": [
    "### ヒストリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e355d6-3241-4948-8e6b-26d59aabbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90b217-2e4a-4240-89a9-cd8350bc0a63",
   "metadata": {},
   "source": [
    "### プロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069b207-c8b7-4e87-8ce2-d0c24ddbeccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot = df.plot(y='loss', title='Loss vs. Epochs', legend=False)\n",
    "loss_plot.set(xlabel='Epochs', ylabel='Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661b58b-141d-45e7-9087-2da0f4df22a9",
   "metadata": {},
   "source": [
    "### 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98cb15-6990-4f51-8b9b-341077317a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812bfe24-dfcf-4d4c-870e-361c229af1ba",
   "metadata": {},
   "source": [
    "### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfe18d1-334d-4aef-b989-303d6b669922",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images[5][np.newaxis,...,np.newaxis])\n",
    "print(predictions)\n",
    "print(labels[np.argmax(predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5954a73b-e29c-4a70-84c4-cb2a70585060",
   "metadata": {},
   "source": [
    "### weight初期値いろいろ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d2882-1c0e-47b3-bd9b-59b2f1cb9053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv1D, MaxPooling1D \n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=16, kernel_size=3, input_shape=(128, 64), kernel_initializer='random_uniform', bias_initializer=\"zeros\", activation='relu'),\n",
    "    MaxPooling1D(pool_size=4),\n",
    "    Flatten(),\n",
    "    Dense(64, kernel_initializer='he_uniform', bias_initializer='ones', activation='relu'),\n",
    "])\n",
    "\n",
    "model.add(Dense(64, \n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "                bias_initializer=tf.keras.initializers.Constant(value=0.4), \n",
    "                activation='relu'),)\n",
    "\n",
    "model.add(Dense(8, \n",
    "                kernel_initializer=tf.keras.initializers.Orthogonal(gain=1.0, seed=None), \n",
    "                bias_initializer=tf.keras.initializers.Constant(value=0.4), \n",
    "                activation='relu'))\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "def my_init(shape, dtype=None):\n",
    "    return K.random_normal(shape, dtype=dtype)\n",
    "model.add(Dense(64, kernel_initializer=my_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f0d152-d89b-40c7-90dd-929b4e4acb3d",
   "metadata": {},
   "source": [
    "### アクティベーション関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab523c-c2f5-4d80-834b-7f8f44151b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([0.0,1.0,1.0])\n",
    "y_pred = tf.constant([0.4,0.8, 0.3])\n",
    "accuracy = K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "print(accuracy)\n",
    "\n",
    "y_true = tf.constant([[0.0,1.0],[1.0,0.0],[1.0,0.0],[0.0,1.0]])\n",
    "y_pred = tf.constant([[0.4,0.6], [0.3,0.7], [0.05,0.95],[0.33,0.67]])\n",
    "accuracy =K.mean(K.equal(y_true, K.round(y_pred)))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc169b78-c573-47cb-9e16-b1127b3c77a8",
   "metadata": {},
   "source": [
    "### ワンホットエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2adf7d-182b-40f7-9a76-26de109aa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0, 1, 5, 8, 10, 9, 1, 3, 4, 2, 6, 7]\n",
    "onehot = tf.keras.utils.to_categorical(labels)\n",
    "print(onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc864173-7d26-4f4c-ac02-5d53a40e415e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 畳み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347c9de-4c87-423f-b4f4-23eb8478556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23be52da-5190-425f-a0b3-9811961dc439",
   "metadata": {},
   "source": [
    "### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3976c7-3cfb-4073-b6c2-afecc31dac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 畳み込みレイヤー。フィルター数16、畳み込みカーネルの形状：(3,3)\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    # MaxPoolingレイヤー。プーリングウィンドウサイズ：(3,3)\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd97615c-b930-440e-9a7a-9f56135f5c0c",
   "metadata": {},
   "source": [
    "### kernel_size, pool_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265ee2fa-2bc6-49b1-99f2-d78c290c9781",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # 次元のサイズが同じ場合は、kernel_size, pool_size で記述できる。\n",
    "    Conv2D(16, kernel_size=3, activation='relu', input_shape=(32, 32, 3)),\n",
    "    # 次元のサイズが同じ場合は、kernel_size, pool_size で記述できる。\n",
    "    MaxPooling2D(pool_size=3),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad61bd3-b96b-45bb-9569-fa3bf1255408",
   "metadata": {},
   "source": [
    "### パディング、ストライド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6c5ed-9102-4e3a-aa53-a47d8c128334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), padding='SAME', strides=2, activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338504e-fbbe-4ce8-8503-bf34d46a380c",
   "metadata": {},
   "source": [
    "### チャンネルの順序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498e124b-9a20-43a0-98a4-6133352d7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # channels_lastの場合、(バッチサイズ, 高さ, 幅, チャンネル数)となる。\n",
    "    # channels_firstの場合、(バッチサイズ, チャンネル数, 高さ, 幅)となる。\n",
    "    Conv2D(16, (3, 3),activation='relu', input_shape=(32, 32, 3), data_format='channels_last'),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024941-7a0d-422d-8b77-59a11c5df86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5499c98-ebaf-496c-8c59-e5b24e18b3e2",
   "metadata": {},
   "source": [
    "# 正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122fe59-a028-426b-980d-cdeec406d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重み行列をカーネルともいう\n",
    "# L1\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          kernel_regularizer=tf.keras.regularizers.l1(0.005)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# L2\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# 両方、かつバイアス正則化\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu',\n",
    "          # 減衰係数：0.001\n",
    "          kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.005, l2=0.001),\n",
    "          bias_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# L2正則化は安定性を高め、L1正則化は特徴選択の役割を果たす"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b15fba-adb9-404f-990f-4cacc3aae7c6",
   "metadata": {},
   "source": [
    "## ドロップアウト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77418d04-ba6c-4fb9-9ab1-926adba5c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    # 前後のレイヤーの接続は0.5の確率でゼロに設定される\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "# トレーニング時はランダムにドロップアウトされる\n",
    "# fit() はトレーニングモード、evaluate(), predict() はテストモードで自動的に処理される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2583ece7-ba31-463f-9623-bd50c9e8d5b7",
   "metadata": {},
   "source": [
    "## バッチ正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f87d51-9d0c-42a5-ae4d-768436a32f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=[train_data.shape[1],], activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea548f78-9813-4cfe-95f3-af5dd5807bc2",
   "metadata": {},
   "source": [
    "### バッチ正則化のカスタマイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e94238-c99e-4548-ba19-0dbdc0f2d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.BatchNormalization(\n",
    "    momentum=0.95, \n",
    "    epsilon=0.005,\n",
    "    axis = -1,\n",
    "    beta_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05), \n",
    "    gamma_initializer=tf.keras.initializers.Constant(value=0.9)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1ffa4a-b9fb-4886-ae0e-8182ba34b03e",
   "metadata": {},
   "source": [
    "# コールバック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b2795-366a-493b-a0a8-c5a655804072",
   "metadata": {},
   "source": [
    "### トレーニング用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c9988-0423-4271-9e17-08b1a546aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class my_callback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        print('train start')\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if batch %2 ==0:\n",
    "            print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('Epoch {}: Average loss is {:7.2f}, mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, callbacks=[my_callbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf6704-6bc3-4b3d-8f2f-2c16a185d9df",
   "metadata": {},
   "source": [
    "### テスト用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b0a89-3ff4-47d2-bf0a-83f06f89abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testing_callback(Callback):\n",
    "    def on_test_begin(self, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    def on_test_end(self, epoch, logs=None):\n",
    "        pass\n",
    "\n",
    "model.evaluate(X_test, y_test, epochs=5, verbose=False, callbacks=[testing_callbacks()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1af74a-a0ec-47a5-a592-1996a9e924a1",
   "metadata": {},
   "source": [
    "※predict用もあるが、同様なので省略。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efac1d-c327-4077-a1ed-e50cd8f3ad28",
   "metadata": {},
   "source": [
    "### エポックの経過で学習率を変化させるコールバック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829c6c0-6b9e-43ca-a41d-619328e8184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = [\n",
    "    (4, 0.03), (7, 0.02), (11, 0.005), (15, 0.007)\n",
    "]\n",
    "\n",
    "def get_new_epoch_lr(epoch, lr):\n",
    "    # Checks to see if the input epoch is listed in the learning rate schedule \n",
    "    # and if so, returns index in lr_schedule\n",
    "    epoch_in_sched = [i for i in range(len(lr_schedule)) if lr_schedule[i][0]==int(epoch)]\n",
    "    if len(epoch_in_sched)>0:\n",
    "        # If it is, return the learning rate corresponding to the epoch\n",
    "        return lr_schedule[epoch_in_sched[0]][1]\n",
    "    else:\n",
    "        # Otherwise, return the existing learning rate\n",
    "        return lr\n",
    "\n",
    "class LRScheduler(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, new_lr):\n",
    "        super(LRScheduler, self).__init__()\n",
    "        # Add the new learning rate function to our callback\n",
    "        self.new_lr = new_lr\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # Make sure that the optimizer we have chosen has a learning rate, and raise an error if not\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "              raise ValueError('Error: Optimizer does not have a learning rate.')\n",
    "                \n",
    "        # Get the current learning rate\n",
    "        curr_rate = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "        \n",
    "        # Call the auxillary function to get the scheduled learning rate for the current epoch\n",
    "        scheduled_rate = self.new_lr(epoch, curr_rate)\n",
    "\n",
    "        # Set the learning rate to the scheduled learning rate\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_rate)\n",
    "        print('Learning rate for epoch {} is {:7.3f}'.format(epoch, scheduled_rate))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112517f2-b5d7-4664-85bf-c368565f2ee0",
   "metadata": {},
   "source": [
    "### 早期打ち切り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80c365-def1-4c34-8dca-e83e5b11ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accurracy', patience=5, min_delta=0.01, mode='max')\n",
    "model.fit(x, y, epochs=100, validation_split=0.15, batch_size=64,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d78f7b-1c33-443f-a59c-8ebbf1bbc720",
   "metadata": {},
   "source": [
    "### ReduceLROnPlateauによる学習率自動調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9719f22-60e4-4385-ae03-22330072eadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# ReduceLROnPlateau が学習率を自動的に調整する\n",
    "def get_callbacks():\n",
    "    early = EarlyStopping(patience=30, mode='min')\n",
    "    reduce = ReduceLROnPlateau(factor=0.2, patience=20)\n",
    "    return (early, reduce)\n",
    "\n",
    "early_stopping, learning_rate_reduction = get_callbacks()\n",
    "history = model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
    "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)\n",
    "\n",
    "print(learning_rate_reduction.patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a707ec7-e65a-42a9-b001-c1b1588772c1",
   "metadata": {},
   "source": [
    "# セーブとロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d2b12-8c90-4eb1-af10-ce4ce667bb95",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250c586-ac3e-4705-9569-6ef277d93fe3",
   "metadata": {},
   "source": [
    "### ウェイトのみ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ede512-631b-46f9-9355-ad2d9a762bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(...)\n",
    "model.fit(X, y, epochs=10)\n",
    "\n",
    "model.save_weights('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ad3d11-561b-4488-9dfb-6647e7001bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復元時、モデルを構築しなおす必要がある\n",
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(...)\n",
    "\n",
    "new_model = model.load_weights('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f44eb76-9960-4421-87c7-313c4b9968d4",
   "metadata": {},
   "source": [
    "### すべて保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e79177-461e-44b5-8e8e-9ecb152c3bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68204196-ae41-40cd-b6be-58a61101817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 復元するときは、モデルを構築しなおす必要が無い\n",
    "new_model = load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b73cd1-c530-4452-bd01-cdfdabd351bc",
   "metadata": {},
   "source": [
    "## チェックポイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e27950-4a90-48a3-8244-ee3887372abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(10,)),\n",
    "    Dense(1)\n",
    "])\n",
    "checkpoint = ModelCheckpoint('my_model', save_weights_only=True)\n",
    "model.fit(X, y, epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4d1cb-5e13-44be-a8d9-601ce55c2ea8",
   "metadata": {},
   "source": [
    "上記の場合、3つのファイルが生成される  \n",
    "checkopint  ・・・実際のモデルがどこに保存されているかを示すメタデータ  \n",
    "my_model.index  ・・・どのウェイトがどこに保存されているかを示す（分散環境で）  \n",
    "my_model.data-00000-of-00001  ・・・実際のウェイトが保存されている  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cdbf44-558f-41b5-9f95-e114bf8f51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras H5形式で保存\n",
    "# ただし、一般的にはネイティブのTensorFlow形式を推奨\n",
    "checkpoint = ModelCheckpoint('keras_model.h5', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d905b9f-a5d8-4deb-b840-0966e7ff376f",
   "metadata": {},
   "source": [
    "keras_model.h5　　・・・HDF5ファイル（ウェイトのみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1f1c3-613c-4ef1-ad5f-9a6ebeb64cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ウェイト以外も保存する\n",
    "checkpoint = ModelCheckpoint('my_model', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8b7f5-a2cd-4cbf-a070-dd6b79d6ed96",
   "metadata": {},
   "source": [
    "この場合、サブディレクトリの下に次のファイルが生成される  \n",
    "my_model/assets/  ・・・グラフで使用されるファイルが保存されるサブディレクトリ  \n",
    "my_model/saved_model.pb  ・・・TensorFlowグラフ自体（モデルアーキテクチャ）を保存  \n",
    "my_model/variables/variables.data-00000-of-00001  ・・・ウェイト  \n",
    "my_model/variables/variables.index  ・・・ウェイトの場所  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c4bdc-d78b-4889-b004-81910a93bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5でウェイト以外も\n",
    "checkpoint = ModelCheckpoint('keras_model.h5', save_weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790dae6-b51f-4b40-bc2f-7a5dd7fd05e7",
   "metadata": {},
   "source": [
    "keras_model.h5　　・・・HDF5ファイル（アーキテクチャ全体が含まれる）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8505af-f15b-4146-8016-0c8fc5da3009",
   "metadata": {},
   "source": [
    "### チェックポイントの復元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a2ecf-5006-4488-b04b-41fbc56c1416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルは再構築しておく必要がある\n",
    "model.load_weights('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c574f9-ce17-43e8-874f-9a0353a0d9c5",
   "metadata": {},
   "source": [
    "### チェックポイントの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a7b32-bb66-46ac-8e26-ab0e08c9e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存頻度（デフォルトはエポック毎）\n",
    "# 最後に重みを保存してからモデルが見たサンプル数で指定\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model', save_weights_only=True,\n",
    "                            save_freq=1000)\n",
    "\n",
    "# パフォーマンス測定基準に従ってのみ保存\n",
    "# 下記の場合、検証損失がトレーニング実行で最高の値になった場合のみ保存する\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model', save_weights_only=True,\n",
    "                            save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# ログディクショナリにあるどんなキーでもフォーマット可能（上書きを防げる）\n",
    "checkpoint = ModelCheckpoint('training_run_1/my_model.{epoch}.{batch}',\n",
    "                             save_weights_only=True, save_freq=1000)\n",
    "checkpoint = ModelCheckpoint('training_run_2/my_model.{epoch}-{val_loss.4f}',\n",
    "                             save_weights_only=True, save_freq=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b42a5a-e237-4a2b-94fd-0a62f41d9cdf",
   "metadata": {},
   "source": [
    "## モデルアーキテクチャのみ保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92100f-12b5-4784-b9ad-32dd433f2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=32, input_shape=(32, 32, 3), activation='relu', name='dense_1'),\n",
    "    Dense(units=10, activation='softmax', name='dense_2')\n",
    "])\n",
    "\n",
    "config_dict = model.get_config()\n",
    "print(config_dict)\n",
    "\n",
    "model_same_config = tf.keras.Sequential.from_config(config_dict)\n",
    "\n",
    "# アーキテクチャは同じ\n",
    "print('Same config:', model.get_config() == model_same_config.get_config())\n",
    "# ウェイトは異なる\n",
    "print('Same value for first weight matrix:', np.allclose(model.weights[0].numpy(), model_same_config.weights[0].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe3b20-b241-4270-ae23-7d1decdfda2e",
   "metadata": {},
   "source": [
    "## 保存形式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223190d-24fc-4e8e-9b55-2b31b1d8cb5a",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34491930-cda8-4322-9d53-3e10a17732b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSONで保存。（ウェイトは含まれない）\n",
    "json_string = model.to_json()\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(json_string, f)\n",
    "del json_string\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    json_string = json.load(f)\n",
    "model_same_config = tf.keras.models.model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b98a69-8882-42b2-b547-02505f7d05e6",
   "metadata": {},
   "source": [
    "### YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296795bb-a2da-4ac3-bb84-1148d6935522",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_string = model.to_yaml()\n",
    "print(yaml_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa872801-2357-400d-99ad-3f60a391056c",
   "metadata": {},
   "source": [
    "# 事前学習されたKerasモデルのロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b33b6-3842-4734-a711-23c0f9fd2f53",
   "metadata": {},
   "source": [
    "## Keras Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7410feb-8466-4ae6-a44a-39fa807787f6",
   "metadata": {},
   "source": [
    "https://keras.io/ja/applications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235c859-fe60-4b20-8c01-ff6485e6a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# imagenetデータセットで学習したモデルが、\n",
    "# ~/.keras/models にウェイト付きでダウンロードされる\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# 全結合層を含まずにダウンロードされる\n",
    "# 転移学習アプリケーションなどに使用できるヘッドモデル\n",
    "model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0475a41-d47e-4d7d-a70a-71f5e86baba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# ResNet50に必要なサイズである224x224に、自動的に変換される\n",
    "img_input = image.load_img('my_picture.jpg', target_size=(224, 224))\n",
    "img_input = image.img_to_array(img_input)\n",
    "img_input = preprocess_input(img_input[np.newaxis, ...])\n",
    "\n",
    "preds = model.predict(img_input)\n",
    "decoded_predictions = decode_predictions(preds, top=3)[0]\n",
    "# List of (class, description, probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735714a6-0944-4571-8ce9-6ace4da07d8e",
   "metadata": {},
   "source": [
    "## TensorFlow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e66db-7cf9-42c8-9dd2-eca3263c052a",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/hub?hl=ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ea34e-50bd-47bc-becf-e7fa5047fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "時間かかるので不用意に実行しない。\n",
    "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v1_050_160/classification/4\"\n",
    "model = Sequential([hub.KerasLayer(module_url)])\n",
    "model.build(input_shape=[None, 160, 160, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c27d4f-f367-4020-9a61-945c40423c1b",
   "metadata": {},
   "source": [
    "# 関数API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2410c5c-8953-41ec-b5e7-7057361f6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "# 損失関数はoutputsと同じ順で２つ指定する\n",
    "# binary_crossentropy + 0.4 * mse が最終的な損失になる\n",
    "model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1, 0.4], metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train, X_aux], [y_train, y_aux], validation_split=0.2, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b30504-616b-442a-a634-dfe0cabb2abd",
   "metadata": {},
   "source": [
    "### モデルを視覚化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904cf0b-75d1-4f62-8b5b-e2056bba39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "plot_model(model, 'multi_input_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb91ee1-364e-4879-a7c3-cf504096c84b",
   "metadata": {},
   "source": [
    "### 変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68096c2b-9fdb-47e3-9cfe-f62c90c46a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_var = tf.Variable([-1, 2], dtype=tf.float32) # 変数の初期値\n",
    "print(my_var)\n",
    "my_var.assign([3.5, -1.])\n",
    "print(my_var)\n",
    "\n",
    "x = my_var.numpy() # numpyに変換\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb9dda-5863-485f-b6f9-1efb3fe41c1f",
   "metadata": {},
   "source": [
    "### テンソル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dec84-762c-461f-80da-24fe44c28e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones(shape=(2, 1))\n",
    "print(x)\n",
    "y = tf.zeros(shape=(2, 1))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db557460-0e61-440d-b4dc-a137ada0cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t= tf.constant(np.arange(24), shape=(3, 2, 4))\n",
    "print(t)\n",
    "t1 = tf.expand_dims(t, 0)\n",
    "print(t1)\n",
    "t2 = tf.expand_dims(t, 1)\n",
    "print(t2)\n",
    "t3 = tf.expand_dims(t, 2)\n",
    "print(t3)\n",
    "\n",
    "print(tf.squeeze(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6ee8e-2c53-45fa-9cc2-8bfb6807a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "d = tf.constant([[1.0, 2.0], [0.0, 1.0]])\n",
    "\n",
    "cd_mutmul = tf.matmul(c, d) # 行列の掛け算\n",
    "print(cd_mutmul)\n",
    "\n",
    "cd_x = c * d # 各要素の掛け算\n",
    "print(cd_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1970b4dd-6125-4848-9d08-369983f4d4a7",
   "metadata": {},
   "source": [
    "### レイヤー変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b02225-a2a8-4a65-81f4-b7b2341ef75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu', name='conv1d_layer')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten()(h)\n",
    "aux_inputs = Input(shape=(12,)) # 補助入力\n",
    "h = Concatenate()([h, aux_inputs])\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "aux_outputs = Dense(1, activation='linear')(h) # 補助出力\n",
    "\n",
    "model = Model(inputs=[inputs, aux_inputs], outputs=[outputs, aux_outputs])\n",
    "\n",
    "model.layers # 全レイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afc99e-34f8-469e-b451-085cbf9f701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].weights) # 特定のレイヤーのウェイト（TensorFlow変数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681edad-28d6-4b3a-a799-8d0ca71f9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].get_weights()) # 単なる数値として取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd0d89-f0a9-4545-aa63-7f09de1c6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].kernel) # カーネル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfbe474-95d0-44f6-b5b0-c6eb95cbbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.layers[1].bias) # バイアス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2285f4-bf99-42aa-a90e-1bd61b4d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_layer('conv1d_layer').bias) # レイヤー名で参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154458ae-7ade-499f-8101-1c254d1dc564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソル\n",
    "print(model.get_layer('conv1d_layer').input)\n",
    "print(model.get_layer('conv1d_layer').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf30910-36ce-4d9e-85d8-7b373cace2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 1))\n",
    "h = Conv1D(16, 5, activation='relu', name='conv1d_layer')(inputs)\n",
    "h = AveragePooling1D(3)(h)\n",
    "h = Flatten(name='flatten_layer')(h)\n",
    "outputs = Dense(20, activation='sigmoid')(h)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "flatten_output = model.get_layer('flatten_layer').output\n",
    "\n",
    "model2 = Model(inputs=model.input, outputs=flatten_output)\n",
    "\n",
    "# 最後のDense層だけ入れ替えた形\n",
    "model3  = Sequential([\n",
    "    model2,\n",
    "    Dense(10, activation='softmax', name='new_dense_layer')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc2c03-98ef-4efc-aee7-a63f39e30db2",
   "metadata": {},
   "source": [
    "### フリーズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02024ed-58bb-469a-b517-04556d3120fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# レイヤーをフリーズ\n",
    "model.get_layer('conv2d_layer').trainable = False\n",
    "model.compile(...)\n",
    "\n",
    "# モデルをフリーズ\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c562a7be-8240-42b8-b62e-f1ba4f8371f3",
   "metadata": {},
   "source": [
    "# データセット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c5278a-7246-4931-a4ff-4e6342558087",
   "metadata": {},
   "source": [
    "### ランダム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a193b-e9cf-4810-ae19-cac9acb5ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random.uniform([256, 4], minval=1, maxval=10, dtype=tf.int32),\n",
    "     tf.random.normal([256]))\n",
    ")\n",
    "print(dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fae63-d8c2-4c27-bad4-15c96cd641ba",
   "metadata": {},
   "source": [
    "## CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d39ac-669f-4a56-9eb3-17c8cbad34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2bc913-96a9-4a85-89b1-948fb3f2bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16885e62-d7fe-462b-b705-7cc946e62766",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[100])\n",
    "print(y_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983546ca-4d00-4782-bb42-b3fff3836552",
   "metadata": {},
   "source": [
    "## ジェネレーター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c537a34-3b20-495e-930f-951cc5bf2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "# datagen は yield でイテレーションのデータを返すデータセット\n",
    "# エポック当たりのステップ数を指定する必要がある\n",
    "model.fit_generator(datagen, steps_per_epoch=1000, epochs=10)\n",
    "\n",
    "model.evaluate_generator(datagen_eval, staps=100)\n",
    "\n",
    "model.predict_generator(datagen_test, steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb25763b-eab9-491c-a063-085f340c78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_datagen = ImageDataGenerator(width_shift_range=0.2, horizontal_flip=True)\n",
    "dataset = tf.data.Dataset.from_generator(img_datagen.flow, args=[x_train, y_train],\n",
    "                                        output_types=(tf.float32, tf.int32),\n",
    "                                        output_shapes=([32, 32, 32, 3], [32, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f1f99-3b17-4597-9345-fd88e127b697",
   "metadata": {},
   "source": [
    "## オーグメンテーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cbf5d-3491-4c70-967f-204120a51868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "image_data_gen = ImageDataGenerator(rescale=1/255., # 範囲を0から1の間にする\n",
    "                                    horizontal_flip=True, # 上下反転して複製\n",
    "                                    height_shift_range=0.1, # 画像の高さの20％の幅でランダムに上下シフト\n",
    "                                    fill_mode='nearest', # 足りないピクセルの埋め方（デフォルト）\n",
    "                                    featurewise_center=True # データセット全体における個々の特徴の平均が0になるよう標準化\n",
    "                                   )\n",
    "\n",
    "image_data_gen.fit(x_train)\n",
    "\n",
    "train_datagen = image_data_gen.flow(x_train, y_train, batch_size=16)\n",
    "\n",
    "model.fit_generator(train_datagen, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc5298-9a26-4775-989b-52af3d330307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monochrome(x):\n",
    "    def func_bv(a):\n",
    "        average_colour = np.mean(a)\n",
    "        return [average_colour, average_colour, average_colour]\n",
    "    x = np.apply_along_axis(func_bv, -1, x)\n",
    "    return x\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "                                    preprocessing_function=monochrome,\n",
    "                                    rotation_range=180,\n",
    "                                    rescale=1/255.\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2654cba-ab30-478d-ba55-eca7c3d8279a",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f40ecc-af38-45ad-9b20-c87df88cfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, labels):\n",
    "    return tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "\n",
    "train_dataset = create_dataset(train_data, train_labels)\n",
    "test_dataset = create_dataset(test_data, test_labels)\n",
    "\n",
    "print(train_dataset.element_spec)\n",
    "print(test_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c760b-ef93-48d0-adee-7881868fe696",
   "metadata": {},
   "source": [
    "## フィルター"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa345ca6-e3cc-45ef-81d7-941e7790f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_classes(dataset, classes):\n",
    "    def filter_func(image, label):\n",
    "        return tf.math.reduce_any(tf.equal(label, classes))\n",
    "    return  dataset.filter(filter_func)\n",
    "\n",
    "cifar_classes = [0, 29, 99] # Your datasets should contain only classes in this list\n",
    "train_dataset = filter_classes(train_dataset, cifar_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f5aad-d7a6-4d16-a932-088b7c8178ef",
   "metadata": {},
   "source": [
    "## ラベルのマッピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481ab97-0d3c-4208-8422-b9696a72b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルをワンホットエンコーディングに変換している\n",
    "def map_labels(dataset):\n",
    "    def one_hot_encode_label(image, label):\n",
    "        num_classes = 3  # クラス数\n",
    "        one_hot_label = tf.one_hot(label, num_classes, on_value=1.0, off_value=0.0)\n",
    "        return image, one_hot_label\n",
    "\n",
    "    return dataset.map(one_hot_encode_label)\n",
    "\n",
    "train_dataset = map_labels(train_dataset)\n",
    "test_dataset = map_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa64c4-b4c9-4f15-8f5b-91e31b4a769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルとエンコーディングの順序を保証する形\n",
    "def map_labels2(dataset):\n",
    "    def one_hot_encode_label(image, label):\n",
    "        encoded_label = tf.zeros(3)\n",
    "        if label == 0:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[0]], [1.0])\n",
    "        elif label == 29:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[1]], [1.0])\n",
    "        elif label == 99:\n",
    "            encoded_label = tf.tensor_scatter_nd_update(encoded_label, [[2]], [1.0])\n",
    "        return image, encoded_label\n",
    "\n",
    "    return dataset.map(one_hot_encode_label)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f06f1-6ee5-406e-a80f-a59fde5841f5",
   "metadata": {},
   "source": [
    "## 時系列ジェネレーター"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee8ce2-8e6c-4d06-81d1-0dcbf0e13d9e",
   "metadata": {},
   "source": [
    "### 動作例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d34b1-6e56-4fc6-833a-6ecce3cf001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dummy_data = np.arange(1, 11, 1)\n",
    "dummy_targets = np.arange(10, 110, 10)\n",
    "print(dummy_data)\n",
    "print(dummy_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc823f3-78a8-40cb-a2e2-dafcf1d6a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, 4)\n",
    "\n",
    "print('Length:', len(timeseries_gen))\n",
    "inputs, outputs = timeseries_gen[0]\n",
    "print(\"\\nData:\")\n",
    "print(inputs)\n",
    "print(\"Targets:\")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81323a44-b0cb-4ae3-acfd-a9e976706d64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### バッチサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93546cea-4bb8-4a00-b835-c8bccfa1808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, batch_size=2)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "next(timeseries_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0917c2-07fb-4cff-9a45-df5db93d051d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ストライド"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f771bb3-a8ca-4304-9c75-c53f4fd023e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, stride=2, batch_size=1)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(next(timeseries_iterator))\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae293643-e73e-42fd-80b7-be2b41582187",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### リバース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a50b96-2b63-4071-962a-18e952f36b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_gen = TimeseriesGenerator(dummy_data, dummy_targets, length=3, stride=1, batch_size=1, reverse=True)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(next(timeseries_iterator))\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae6044-8e56-48aa-8890-e981df328a61",
   "metadata": {},
   "source": [
    "### オーディオ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e736e1c-623a-40f9-97e6-d7f0eaf464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "rate, song = read(\"data/055 - Angels In Amplifiers - I'm Alright/mixture.wav\")\n",
    "print(\"rate:\", rate)\n",
    "song = np.array(song)\n",
    "print(\"song.shape:\", song.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389575f6-12ad-4700-ada5-c2341fb47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_gen = TimeseriesGenerator(song, targets=song, length=200000, stride=200000, batch_size=1)\n",
    "timeseries_iterator = iter(timeseries_gen)\n",
    "\n",
    "for i in range(3):\n",
    "    sample, target = next(timeseries_iterator)\n",
    "    write('example.wav', rate, sample[0])\n",
    "    print('Sample {}'.format(i+1))\n",
    "    ipd.display(ipd.Audio(\"example.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf307933-a419-4904-8b8d-7aa9ce6c14f1",
   "metadata": {},
   "source": [
    "# シーケンシャルデータ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32d06d-5fbb-45af-b9e0-39d8aab7e471",
   "metadata": {},
   "source": [
    "## パディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21f893a-8960-4edd-bbc2-18d5dc9de8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "test_input = [\n",
    "    [4, 12, 33, 18],\n",
    "    [63, 23, 54, 30, 19, 3],\n",
    "    [43, 37, 11, 33, 15]\n",
    "]\n",
    "\n",
    "preprocessed_data = pad_sequences(test_input, padding='pre') # リストのリストを渡す\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbe09b-f4ed-4ae5-abd9-2e8246fee4d9",
   "metadata": {},
   "source": [
    "[[ 0  0  4 12 33 18]  \n",
    " [63 23 54 30 19  3]  \n",
    " [ 0 43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980a59b-4d5a-45ee-95fd-870082142152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大長指定（前を切り捨て）\n",
    "preprocessed_data = pad_sequences(test_input, padding='post', maxlen=5)\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121237a-0e72-475a-b6f7-0aa1a84c3250",
   "metadata": {},
   "source": [
    "[[ 4 12 33 18  0]  \n",
    " [23 54 30 19  3]  \n",
    " [43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed6e20-3448-4b0a-a659-2848f2df70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大長指定（後を切り捨て）\n",
    "preprocessed_data = pad_sequences(test_input, padding='post', maxlen=5, truncating='post')\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab81392-88de-4f38-b53c-6682a95cd9b3",
   "metadata": {},
   "source": [
    "[[ 4 12 33 18  0]  \n",
    " [63 23 54 30 19]  \n",
    " [43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ab16b-d9f2-4e8f-b0c1-24a298e1b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パディング値を指定\n",
    "preprocessed_data = pad_sequences(test_input, value=-1)\n",
    "print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece14e4-724e-4fe2-a7e9-9e0a68ca1a0d",
   "metadata": {},
   "source": [
    "[[-1 -1  4 12 33 18]  \n",
    " [63 23 54 30 19  3]  \n",
    " [-1 43 37 11 33 15]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d7247-9195-45da-bad1-71960ff728e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Masking\n",
    "import numpy as np\n",
    "\n",
    "test_input = [\n",
    "    [4, 12, 33, 18],\n",
    "    [63, 23, 54, 30, 19, 3],\n",
    "    [43, 37, 11, 33, 15]\n",
    "]\n",
    "\n",
    "preprocessed_data = pad_sequences(test_input, padding='post')\n",
    "\n",
    "masking_layer = Masking(mask_value=0)\n",
    "preprocessed_data = preprocessed_data[..., np.newaxis] # (batch_size, seq_length, features)\n",
    "masked_input = masking_layer(preprocessed_data)\n",
    "print(masked_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645ecc4-4e6d-419e-9dfa-eb65f68dc68f",
   "metadata": {},
   "source": [
    "[[[ 4]\n",
    "  [12]\n",
    "  [33]\n",
    "  [18]\n",
    "  [ 0]\n",
    "  [ 0]],  \n",
    " [[63]\n",
    "  [23]\n",
    "  [54]\n",
    "  [30]\n",
    "  [19]\n",
    "  [ 3]],  \n",
    " [[43]\n",
    "  [37]\n",
    "  [11]\n",
    "  [33]\n",
    "  [15]\n",
    "  [ 0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be180e-56fb-4149-8ca4-a5504c50bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_input._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1c69d-b245-421d-88c3-2f6233b5c8e7",
   "metadata": {},
   "source": [
    "<tf.Tensor: shape=(3, 6), dtype=bool, numpy=  \n",
    "array([[ True,  True,  True,  True, False, False],  \n",
    "       [ True,  True,  True,  True,  True,  True],  \n",
    "       [ True,  True,  True,  True,  True, False]])>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c2eca-2a5b-4de1-8969-977539fe8f9a",
   "metadata": {},
   "source": [
    "## 埋め込み層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5c8fd-622e-46a2-9488-4e3f41b86bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "\n",
    "# 1000個の異なるトークンを32次元の浮動小数点ベクトルに埋め込む\n",
    "embedding_layer = Embedding(1000, 32, input_length=64)\n",
    "# 16個のシーケンスで各シーケンスは64個の整数で構成。値は0から999までの範囲。\n",
    "test_input = np.random.randint(1000, size=(16, 64))\n",
    "\n",
    "# 埋め込み層をテストデータに適用し、元の整数シーケンスを32次元浮動小数点ベクトルに変換\n",
    "embedded_inputs = embedding_layer(test_input) # (16, 64, 32)\n",
    "print(embedded_inputs)\n",
    "#embedded_inputs._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b150802-ba40-4f07-b03c-4d7f2816d7ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 再帰ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de84d29-4ba1-4846-9f7f-4d1b8c8c3cd2",
   "metadata": {},
   "source": [
    "### シンプルRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f50c46-96c6-4c1f-8eb9-00effa44f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長64、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32, input_length=64), # (None, 64, 32)\n",
    "    SimpleRNN(64, activation='tanh'),     # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18d883-bd8f-45b3-9332-827ea43adde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 任意のシーケンス長\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    SimpleRNN(64, activation='tanh'),     # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1855f8a7-a812-48b7-980d-b299d8b7c3fb",
   "metadata": {},
   "source": [
    "### LSTM（長・短期記憶）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c09988-28bb-410e-a4b3-9ee74a537ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    LSTM(64, activation='tanh'),          # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b335e-52f9-4420-863e-9740db0134f8",
   "metadata": {},
   "source": [
    "### GRU（ゲート付き反復単位）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da681912-fecf-4c2e-9f42-52d3a8e56c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "model = Sequential([\n",
    "    # 入力：シーケンス長任意、整数トークンの範囲は0から999\n",
    "    Embedding(1000, 32),                  # (None, None, 32)\n",
    "    GRU(64, activation='tanh'),           # (None, 64)\n",
    "    Dense(5, activation='softmax')        # (None, 5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607fe05-9909-48b5-901a-b6fcb37971f6",
   "metadata": {},
   "source": [
    "## スタック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d468b-5bfd-4698-832c-7c78071ce133",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c6130-c2ce-47fd-bb08-b396f8ad54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Input\n",
    "\n",
    "inputs = Input(shape=(None, 10))            # (None, None, 10)\n",
    "h = Masking(mask_value=0)(inputs)           # (None, None, 10)\n",
    "# タイムステップごとに出力を返す\n",
    "h = LSTM(32, return_sequences=True)(h)      # (None, None, 32) \n",
    "h = LSTM(64)(h)                             # (None, 64)\n",
    "outputs = Dense(5, activation='softmax')(h) # (None, 5)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b266d40-124a-4c14-b7c8-71f4a7edc748",
   "metadata": {},
   "source": [
    "### 双方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce63918-514f-40d3-a651-a72186fccf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Input, Bidirectional\n",
    "\n",
    "# 過去だけでなく未来のコンテキストも考慮したいとき、Bidirectionalが使える\n",
    "inputs = Input(shape=(None, 10))                          # (None, None, 10)\n",
    "h = Masking(mask_value=0)(inputs)                          # (None, None, 10)\n",
    "h = Bidirectional(LSTM(32, return_sequences=True))(h)      # (None, None, 64) \n",
    "h = Bidirectional(LSTM(64))(h)                             # (None, 128) \n",
    "outputs = Dense(5, activation='softmax')(h)                # (None, 5)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931f723-b791-4f16-a1ee-57d7cf5c1c7c",
   "metadata": {},
   "source": [
    "# カスタムモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0206cca-b39d-4250-a180-613650415025",
   "metadata": {},
   "source": [
    "## モデルサブクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ffbae-89bb-48b7-9f6c-f289a006b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, num_classes, **kargs):\n",
    "        super(MyModel, self).__init__(**kargs)\n",
    "        self.dense1 = Dense(16, activation='sigmoid')\n",
    "        self.dropout = Dropout(0.5)\n",
    "        self.dense2 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        h = self.dense1(inputs)\n",
    "        h = self.dropout(h, training=training)\n",
    "        return self.dense2(h)\n",
    "\n",
    "my_model = MyModel(10, name='my_model')\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d3d12-c0eb-40de-bade-42a564ca9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(10)\n",
    "        self.dense3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        y1 = self.dense2(inputs)\n",
    "        y2 = self.dense3(y1)\n",
    "        concat = concatenate([x,y2])\n",
    "        return self.softmax(concat)\n",
    "\n",
    "my_model = MyModel()\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dad364-41ba-47dc-807d-2d5e049d1dde",
   "metadata": {},
   "source": [
    "## カスタムレイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfa4cf-7d2a-4730-a21d-fb7e27058ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class LinearMap(Layer):\n",
    "    def __init__(self, input_dim, units):\n",
    "        super(LinearMap, self).__init__()\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(initial_value=w_init(shape=(input_dim, units)))\n",
    " \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "\n",
    "linear_layer = LinearMap(3, 2)\n",
    "print(linear_layer.weights)\n",
    "\n",
    "inputs = tf.ones((1, 3))\n",
    "print(linear_layer(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec6993-a4cb-4a33-8ed0-f12265eca007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムレイヤーを使ったカスタムモデル\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "class MyModel(Model):\n",
    "    def __init__(self, hidden_units, outputs, **kargs):\n",
    "        super(MyModel, self).__init__(**kargs)\n",
    "        self.dense1 = Dense(hidden_units, activation='sigmoid')\n",
    "        self.linear = LinearMap(hidden_units, outputs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        h = self.dense1(inputs)\n",
    "        return self.linear(h)\n",
    "\n",
    "my_model = MyModel(64, 12, name='my_model')\n",
    "my_model(tf.random.uniform([1, 10]))\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430fa28-34d5-4b44-8d42-89dc2da8040b",
   "metadata": {},
   "source": [
    "## 自動微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d0d3d7-4cc9-4784-81e3-95d3e41ea579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x) # 以降のxに対する操作が記録される\n",
    "    y = x**2\n",
    "    grad = tape.gradient(y, x) # xに関して微分したいテンソルを渡し、結果をテンソルgradに格納\n",
    "\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dadba-8564-4e88-9fa5-dada27e9807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_sum(x**2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy = tape.gradient(z, y)\n",
    "\n",
    "print(dz_dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0c702-e002-45e4-8efe-ab6bdc2f7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([0, 1, 2, 3], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_sum(x**2)\n",
    "    z = tf.math.sin(y)\n",
    "    dz_dy, dz_dx = tape.gradient(z, [y, x])\n",
    "\n",
    "print(dz_dy)\n",
    "print(dz_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac4bfe-1837-47bb-b080-fbdab146338d",
   "metadata": {},
   "source": [
    "## カスタムトレーニングループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0394763d-d73c-464e-a462-0c222cb1077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "my_model = MyModel()\n",
    "loss = MeanSquaredError()\n",
    "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_losses = []\n",
    "    \n",
    "    for inputs, outputs in training_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # tape.watch() を実行していない理由は、\n",
    "            # TensorFlow変数オブジェクトを使用する計算がコンテキストによって自動的に記録されるから。\n",
    "            current_loss = loss(my_model(inputs), outputs)\n",
    "            grads = tape.gradient(current_loss, my_model.trainable_variables)\n",
    "    \n",
    "        batch_losses.append(current_loss)\n",
    "        optimizer.apply_gradients(zip(grads, my_model.trainable_variables))\n",
    "\n",
    "    epoch_losses.append(np.mean(batch_losses))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3dcca-1838-4524-b217-5178d2f5c1ae",
   "metadata": {},
   "source": [
    "## tf.function デコレータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254bc2cf-e364-45d3-9c7b-ec8514dc2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "my_model = MyModel()\n",
    "loss = MeanSquaredError()\n",
    "optimizer = SGD(learning_rate=0.05, momentum=0.9)\n",
    "\n",
    "# この関数からグラフが作成されるので、多くの場合、高速に実行される\n",
    "@tf.function\n",
    "def get_loss_and_graph(inputs, outputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(my_model(inputs), outputs)\n",
    "        grads = tape.gradient(current_loss, my_model.trainable_variables)\n",
    "    return current_loss, grads\n",
    "\n",
    "current_loss, grads = get_loss_and_grads(inputs, outputs)\n",
    "optimizer.apply_gradients(zip(grads, my_model.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b22d2f1-3401-4965-a90b-a48b6d4cc9e6",
   "metadata": {},
   "source": [
    "# TensorFlow Probability（TFP 確率的レイヤー）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c23e60-0fa9-4c9b-bd28-bd3acb99b5e3",
   "metadata": {},
   "source": [
    "## 分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728ffd9-dfa7-4f3d-98d5-7eae5943a282",
   "metadata": {},
   "source": [
    "### 一変量分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67443f85-cf68-42ff-8358-df98227a8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "print('正規分布')\n",
    "normal = tfd.Normal(loc=0., scale=1.) # 平均値、標準偏差\n",
    "print(normal)\n",
    "print(normal.sample(3)) # ランダムに3サンプルを生成\n",
    "print(normal.prob(0.5)) # 特定の値の確率密度\n",
    "print(normal.log_prob(0.5)) # 特定の値の確率密度の自然対数\n",
    "\n",
    "print('ベルヌーイ（離散型分布）')\n",
    "bernoulli = tfd.Bernoulli(probs=0.7) # 0と1のうち、1が発生する確率\n",
    "bernoulli = tfd.Bernoulli(logits=0.847) # 対数オッズで指定する方法（確率0.7と同じ）\n",
    "print(bernoulli)\n",
    "print(bernoulli.sample(10))\n",
    "print(bernoulli.prob(1))\n",
    "print(bernoulli.log_prob(1)) # 0.7の対数\n",
    "\n",
    "print('バッチ')\n",
    "batched_bernoulli = tfd.Bernoulli(probs=[0.4, 0.5]) # 1つのオブジェクトに複数の確率分布を作成\n",
    "print(batched_bernoulli)\n",
    "print(batched_bernoulli.sample(3))\n",
    "print(batched_bernoulli.prob([1, 1]))\n",
    "print(batched_bernoulli.log_prob([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633138e1-eeed-4225-a5bf-7c7c1508663e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2Dバッチ')\n",
    "probs = [[[0.5, 0.5],\n",
    "         [0.8, 0.3],\n",
    "         [0.25, 0.75]]]\n",
    "batched_bernoulli_2d = tfd.Bernoulli(probs=probs)\n",
    "print(batched_bernoulli_2d)\n",
    "print(batched_bernoulli_2d.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a64ac-bd6b-4df7-a6a8-9ba59ff5a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒストグラムプロット\n",
    "plt.hist(normal.sample(10000), bins=50, density=True) # 棒の数、総和が1になるよう正規化\n",
    "plt.show()\n",
    "\n",
    "exponential = tfd.Exponential(rate=1)\n",
    "plt.hist(exponential.sample(10000), bins=50, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce6783-5897-4c94-bc43-a82fc999ac76",
   "metadata": {},
   "source": [
    "### 多変量分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2829b0b8-d31a-46c7-abd3-9aea4f87ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "print('対角共分散行列を持つ多変量正規分布')\n",
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1., 0.5], scale_diag=[1., 1.5]) # 平均、標準偏差\n",
    "print(mv_normal) # batch_shape=[], event_shape=[2]\n",
    "print(mv_normal.sample(3))\n",
    "print(mv_normal.log_prob([-0.2, 1.8])) # まとめて1つの確率変数の値を表す\n",
    "\n",
    "print('バッチとの違い')\n",
    "batched_normal = tfd.Normal(loc=[-1., 0.5], scale=[1., 1.5])\n",
    "print(batched_normal) # batch_shape=[2], event_shape=[]\n",
    "print(batched_normal.sample(3))\n",
    "print(batched_normal.log_prob([-0.2, 1.8])) # それぞれの確率変数の値を表す（合計すると多変量の値と等しい）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1518c15-8ade-45c0-a5a7-532085b4cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチ化された多変量分布\n",
    "batched_mv_normal = tfd.MultivariateNormalDiag(\n",
    "    loc = [[-1., 0.5], [2., 0.], [-0.5, 1.5]],\n",
    "    scale_diag = [[1., 1.5], [2., 0.5], [1., 1.]]\n",
    ")\n",
    "print(batched_mv_normal) # batch_shape=[3], event_shape=[2]\n",
    "print(batched_mv_normal.sample(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e0afd-e0e2-4b79-99cd-0ea3550eed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# プロット\n",
    "mv_normal = tfd.MultivariateNormalDiag(loc=[-1., 0.5], scale_diag=[1., 1.5])\n",
    "plt_sample = mv_normal.sample(10000)\n",
    "plt.scatter(plt_sample[:, 0], plt_sample[:, 1], marker='.', alpha=0.05)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ab79f-6074-4f8a-bca8-2b151a2a52d3",
   "metadata": {},
   "source": [
    "### 独立分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c330e-643f-42db-9758-d3134ffb2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "batched_normal = tfd.Normal(loc=[-1., 0.5], scale=[1., 1.5])\n",
    "print(batched_normal)\n",
    "print(batched_normal.log_prob([0.2, 1.8]))\n",
    "\n",
    "# 二次元を独立した一次元に変換\n",
    "independent_normal = tfd.Independent(batched_normal, reinterpreted_batch_ndims=1)\n",
    "print(independent_normal)\n",
    "print(independent_normal.log_prob([0.2, 1.8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043e717-fbbf-46ae-8747-402c8c54bf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "batched_normal = tfd.Normal(\n",
    "    loc = [[-1., 0.5], [0., 1.], [0.3, -0.1]],\n",
    "    scale = [[1., 1.5], [0.2, 0.8], [2., 1.]]\n",
    ")\n",
    "print(batched_normal)\n",
    "\n",
    "independent_normal = tfd.Independent(batched_normal, reinterpreted_batch_ndims=1)\n",
    "print(independent_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b0c8f-cfcd-4345-a27c-c2f0e9093c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "exp = tfd.Exponential(rate=[\n",
    "    [[[1., 1.5, 0.8], [0.3, 0.4, 1.8]]],\n",
    "    [[[0.2, 0.4, 1.4], [0.4, 1.1, 0.9]]]\n",
    "])\n",
    "print(exp)\n",
    "ind_exp = tfd.Independent(exp, reinterpreted_batch_ndims=2)\n",
    "print(ind_exp)\n",
    "print(ind_exp.sample([4, 2]).shape)\n",
    "\n",
    "print(ind_exp.log_prob(tf.random.uniform((5, 1, 1, 2, 1))).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6ce719-b720-409c-aab0-2de8fa5a080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "201e3dd8-fb03-4a4b-8702-82dbd4caba52",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5781405-1598-49c4-8a30-ab6fe7cea7ab",
   "metadata": {},
   "source": [
    "## ナイーブベイズ分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae655de-c6b6-4ccd-88cf-147b2938b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, model_selection\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b4270-d80f-4ddf-9227-cf0da9e852c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Irisデータセット\n",
    "iris = datasets.load_iris()\n",
    "data = iris.data[:, :2]\n",
    "targets = iris.target\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data, targets, test_size=0.2)\n",
    "\n",
    "labels = {0: 'Iris-Setosa', 1: 'Iris-Versicolour', 2: 'Iris-Virginica'}\n",
    "label_colours = ['blue', 'orange', 'green']\n",
    "\n",
    "def plot_data(x, y, labels, colours):\n",
    "    for c in np.unique(y):\n",
    "        inx = np.where(y == c)\n",
    "        plt.scatter(x[inx, 0], x[inx, 1], label=labels[c], c=colours[c])\n",
    "    plt.title(\"Training set\")\n",
    "    plt.xlabel(\"Sepal length (cm)\")\n",
    "    plt.ylabel(\"Sepal width (cm)\")\n",
    "    plt.legend()\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_data(x_train, y_train, labels, label_colours)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515416b-1e36-4ae8-a289-f7ad3cc72565",
   "metadata": {},
   "source": [
    "### クラス事前分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a174dc-3902-4106-a151-e0932c15e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yデータから確率分布を生成する\n",
    "def get_prior(y):\n",
    "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "    #print(unique_labels, label_counts) # [0 1 2] [40 43 37]\n",
    "    class_probabilities = label_counts / len(y)\n",
    "    #print(class_probabilities) # [0.33333333 0.35833333 0.30833333]\n",
    "    return tfp.distributions.Categorical(probs=class_probabilities)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f74f16-1131-440b-bf8d-2ec4026f888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = get_prior(y_train)\n",
    "\n",
    "labels = ['Iris-Setosa', 'Iris-Versicolour', 'Iris-Virginica']\n",
    "plt.bar([0, 1, 2], prior.probs.numpy(), color=label_colours)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Prior probability\")\n",
    "plt.title(\"Class prior distribution\")\n",
    "plt.xticks([0, 1, 2], labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba33ac1-195a-4dc9-8cb2-70fc10619f4a",
   "metadata": {},
   "source": [
    "### クラス条件付き確率密度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec3e2e6-ee99-47f6-85e7-9f443b71fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_conditionals(x, y):\n",
    "    num_samples, num_features = x.shape\n",
    "    num_classes = np.max(y) + 1\n",
    "\n",
    "    # クラスごとの平均値、標準偏差を保持するリスト\n",
    "    mean_tensors = []\n",
    "    std_dev_tensors = []\n",
    "    \n",
    "    for class_label in range(num_classes):\n",
    "        class_data = x[y == class_label] # 指定クラスのデータのみ抽出\n",
    "        \n",
    "        class_means = tf.reduce_mean(class_data, axis=0)\n",
    "        class_std_devs = tf.math.reduce_std(class_data, axis=0)\n",
    "        \n",
    "        mean_tensors.append(class_means)\n",
    "        std_dev_tensors.append(class_std_devs)\n",
    "    \n",
    "    class_means_tensor = tf.stack(mean_tensors)\n",
    "    class_std_devs_tensor = tf.stack(std_dev_tensors)\n",
    "    #print(class_means_tensor)\n",
    "    #print(class_std_devs_tensor)\n",
    "    \n",
    "    class_conditionals_distribution = tfp.distributions.MultivariateNormalDiag(\n",
    "        loc=class_means_tensor,\n",
    "        scale_diag=class_std_devs_tensor,\n",
    "    )\n",
    "    #print(class_conditionals_distribution) # batch_shape=[3], event_shape=[2]\n",
    "    return class_conditionals_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f254cf-3f19-4505-9a8c-71560c15dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_conditionals = get_class_conditionals(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bceddc-0347-4a85-b49d-cfb15d9b872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meshgrid(x0_range, x1_range, num_points=100):\n",
    "    x0 = np.linspace(x0_range[0], x0_range[1], num_points)\n",
    "    x1 = np.linspace(x1_range[0], x1_range[1], num_points)\n",
    "    return np.meshgrid(x0, x1)\n",
    "\n",
    "def contour_plot(x0_range, x1_range, prob_fn, batch_shape, colours, levels=None, num_points=100):\n",
    "    X0, X1 = get_meshgrid(x0_range, x1_range, num_points=num_points)\n",
    "    Z = prob_fn(np.expand_dims(np.array([X0.ravel(), X1.ravel()]).T, 1))\n",
    "    Z = np.array(Z).T.reshape(batch_shape, *X0.shape)\n",
    "    for batch in np.arange(batch_shape):\n",
    "        if levels:\n",
    "            plt.contourf(X0, X1, Z[batch], alpha=0.2, colors=colours, levels=levels)\n",
    "        else:\n",
    "            plt.contour(X0, X1, Z[batch], colors=colours[batch], alpha=0.3)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_data(x_train, y_train, labels, label_colours)\n",
    "x0_min, x0_max = x_train[:, 0].min(), x_train[:, 0].max()\n",
    "x1_min, x1_max = x_train[:, 1].min(), x_train[:, 1].max()\n",
    "contour_plot((x0_min, x0_max), (x1_min, x1_max), class_conditionals.prob, 3, label_colours)\n",
    "plt.title(\"Training set with class-conditional density contours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af58611-95f5-4822-8056-b4a2366aa3fa",
   "metadata": {},
   "source": [
    "### 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3d947-680e-4b38-81bd-45c049ec6101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス事前分布とクラス条件付き確率密度の和が最大となるクラスを求める\n",
    "def predict_class(prior, class_conditionals, x):\n",
    "    X = np.expand_dims(x, axis=(x.ndim - 1))\n",
    "    cond_probs = class_conditionals.log_prob(X)\n",
    "    prior_log = np.log(prior.probs)\n",
    "    joint_likelihood = tf.add(cond_probs, prior_log)\n",
    "    #print(joint_likelihood)\n",
    "    return np.argmax(joint_likelihood, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014179e-8e06-4599-8ca5-d214050b8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_class(prior, class_conditionals, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bd0eb-9fb3-410c-a983-85995be8b7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b796b2b-fa46-42e9-979f-9a25757a0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_data(x_train, y_train, labels, label_colours)\n",
    "x0_min, x0_max = x_train[:, 0].min(), x_train[:, 0].max()\n",
    "x1_min, x1_max = x_train[:, 1].min(), x_train[:, 1].max()\n",
    "# 等高線プロット\n",
    "contour_plot((x0_min, x0_max), (x1_min, x1_max), \n",
    "             lambda x: predict_class(prior, class_conditionals, x), \n",
    "             1, label_colours, levels=[-0.5, 0.5, 1.5, 2.5],\n",
    "             num_points=500)\n",
    "plt.title(\"Training set with decision regions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357c8d-efe7-4e1b-85c9-f3361eba9c72",
   "metadata": {},
   "source": [
    "### バイナリ分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1772536-9754-4465-9e20-ff3f84432599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3クラスだったデータを2クラスに変更している\n",
    "y_train_binary = np.array(y_train)\n",
    "y_train_binary[np.where(y_train_binary == 2)] = 1\n",
    "\n",
    "y_test_binary = np.array(y_test)\n",
    "y_test_binary[np.where(y_test_binary == 2)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35d7f3-3e9d-406f-8a1b-0b5ea4448318",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_binary = {0: 'Iris-Setosa', 1: 'Iris-Versicolour / Iris-Virginica'}\n",
    "label_colours_binary = ['blue', 'red']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot_data(x_train, y_train_binary, labels_binary, label_colours_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55d512-2508-4608-bbb9-ce437e438ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス事前分布\n",
    "prior_binary = get_prior(y_train_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4e21e-bb54-476d-b39e-f96d094f315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0, 1], prior_binary.probs.numpy(), color=label_colours_binary)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Prior probability\")\n",
    "plt.title(\"Class prior distribution\")\n",
    "plt.xticks([0, 1], labels_binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebf208-d702-4f16-b768-4e490619ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_stdevs(x, y, scales, optimiser, epochs):\n",
    "    shape = (len(set(y)), x.shape[-1])\n",
    "    loc = np.zeros(shape, dtype=np.float32)\n",
    "\n",
    "    for feature in range(shape[0]):\n",
    "        for category in range(shape[-1]):\n",
    "            data_point = x[y == category][:, feature]\n",
    "            loc[category, feature] = np.mean(data_point)\n",
    "\n",
    "    distribution = tfd.MultivariateNormalDiag(loc=loc, scale_diag=scales)\n",
    "\n",
    "    x_new = x.astype('float32')\n",
    "    x_new = np.expand_dims(x_new, 1)\n",
    "\n",
    "    # 負の対数尤度関数\n",
    "    def nll(x, y, distribution):\n",
    "        predictions = - distribution.log_prob(x)\n",
    "        p1 = tf.reduce_sum(predictions[y==0][:,0])\n",
    "        p2 = tf.reduce_sum(predictions[y==1][:,1])\n",
    "        return p1 + p2\n",
    "\n",
    "    @tf.function\n",
    "    def get_loss_and_grads(x, y, distribution):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(distribution.trainable_variables)\n",
    "            loss = nll(x, y, distribution)\n",
    "            grads = tape.gradient(loss, distribution.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    train_loss_results = []\n",
    "    train_scale_results = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'epoch: {epoch}')\n",
    "        loss, grads = get_loss_and_grads(x_new, y, distribution)\n",
    "        optimiser.apply_gradients(zip(grads, distribution.trainable_variables))\n",
    "        scales = distribution.parameters['scale_diag'].numpy()\n",
    "        train_loss_results.append(loss)\n",
    "        train_scale_results.append(scales)\n",
    "\n",
    "    return np.array(train_loss_results), np.array(train_scale_results), distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead3e5a-4040-4d0e-97fb-82cf2f7d18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = tf.Variable([1., 1.])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "epochs = 500\n",
    "\n",
    "nlls, scales_arr, class_conditionals_binary = learn_stdevs(x_train, y_train_binary, scales, opt, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5b963-4bc9-48d6-84ef-9c70bed4783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Class conditional means:\")\n",
    "print(class_conditionals_binary.loc.numpy())\n",
    "print(\"\\nClass conditional standard deviations:\")\n",
    "print(class_conditionals_binary.stddev().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987be1fc-5fc3-4cef-961a-2cbe70d41a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax[0].plot(nlls)\n",
    "ax[0].set_title(\"Loss vs epoch\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Average negative log-likelihood\")\n",
    "for k in [0, 1]:\n",
    "    ax[1].plot(scales_arr[:, k], color=label_colours_binary[k], label=labels_binary[k])\n",
    "ax[1].set_title(\"Standard deviation ML estimates vs epoch\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"Standard deviation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee97718-593a-4b9c-94b8-924d838fe869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_data(x_train, y_train_binary, labels_binary, label_colours_binary)\n",
    "x0_min, x0_max = x_train[:, 0].min(), x_train[:, 0].max()\n",
    "x1_min, x1_max = x_train[:, 1].min(), x_train[:, 1].max()\n",
    "contour_plot((x0_min, x0_max), (x1_min, x1_max), class_conditionals_binary.prob, 2, label_colours_binary)\n",
    "plt.title(\"Training set with class-conditional density contours\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95492d1d-793b-4e79-bacc-027bc4cf2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plot_data(x_train, y_train_binary, labels_binary, label_colours_binary)\n",
    "x0_min, x0_max = x_train[:, 0].min(), x_train[:, 0].max()\n",
    "x1_min, x1_max = x_train[:, 1].min(), x_train[:, 1].max()\n",
    "contour_plot((x0_min, x0_max), (x1_min, x1_max), \n",
    "             lambda x: predict_class(prior_binary, class_conditionals_binary, x), \n",
    "             1, label_colours_binary, levels=[-0.5, 0.5, 1.5],\n",
    "             num_points=500)\n",
    "plt.title(\"Training set with decision regions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093dbf1a-4231-426c-b724-2c0accd92c2b",
   "metadata": {},
   "source": [
    "## DistributionLambda レイヤー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65a6334-b8fb-4e6f-b285-9d6d002c4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1, input_shape=(2,)),\n",
    "    tfpl.DistributionLambda(\n",
    "        lambda t: tfd.Normal(loc=t, scale=1)\n",
    "    )\n",
    "])\n",
    "\n",
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "model.comile(loss=nll, optimizer='rmsprop')\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "model(x_test).sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dd332-02e1-448d-9ea1-9fa6dfb5b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(8,)),\n",
    "    Dense(2),\n",
    "    tfpl.IndependentNormal(1)\n",
    "])\n",
    "\n",
    "model.comile(loss=lambda y_true, ypred: -y_pred.log_prob(y_true))\n",
    "model.fit(x_train, y_train, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde8eaa-545b-4ad3-ade9-7dae432b2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return lambda t: tfd.Independent(tfd.Normal(loc=tf.zeros(n, dtype=dtype), scale=1),\n",
    "                                    reinterpreted_batch_ndims=1)\n",
    "\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return Sequential([\n",
    "        tfpl.VariableLayer(tfpl.IndependentNormal.params_size(n), dtype=dtype),\n",
    "        tfpl.IndependentNormal(n, convert_to_tensor_fn=tfd.Distribution.sample)\n",
    "    ])\n",
    "\n",
    "# Nはデータセットのサイズ\n",
    "model = Sequential([\n",
    "    tfpl.DenseVariational(16, posterior, prior, kl_weight=1/N,\n",
    "                         activation='relu', input_shape=(8,)),\n",
    "    tfpl.DenseVariational(2, posterior, prior, kl_weight=1/N),\n",
    "    tfpl.IndependentNormal(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fbb28-921e-4c1c-897d-ba58a958b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool2D, Flatten\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "\n",
    "model = Sequential([\n",
    "    tfpl.Convolution2DReparameterization(16, [3, 3],\n",
    "                    activation='relu', input_shape=(28, 28, 1),\n",
    "                    kernel_posterior_fn=tfpl.default_mean_field_normal_fn(),\n",
    "                    kernel_prior_fn=tfpl.default_multivariate_normal_fn),\n",
    "    MaxPool2D(3),\n",
    "    Flatten(),\n",
    "    tfpl.DenseReparameterization(tfpl.OneHotCategorical.params_size(10)),\n",
    "    tfpl.OneHotCategorical(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc5228-214d-4a5c-b78c-5e37d2026249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e22273-3b02-4c5d-8c39-e93e3d519af1",
   "metadata": {},
   "source": [
    "# バイジェクターと正規化フロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d47a25-31fe-48c8-91c9-850c0144ea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 4. 6.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([2.5 1.5 0.5], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "z = tf.constant([1., 2., 3.])\n",
    "\n",
    "scale = tfb.Scale(2.)\n",
    "\n",
    "x = scale.forward(z)\n",
    "print(x)\n",
    "\n",
    "y = scale.inverse(tf.constant([5., 3., 1.]))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9c72e0-b60d-4392-a539-71a0f14b89fd",
   "metadata": {},
   "source": [
    "### チェイン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0902043-13d9-4d95-8caf-6b7ae6c041f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3. 5. 7.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0.5 2.  3.5], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "z = tf.constant([1., 2., 3.])\n",
    "\n",
    "scale = tfb.Scale(2.)\n",
    "shift = tfb.Shift(1.)\n",
    "\n",
    "scale_and_shift = tfb.Chain([shift, scale]) # リストとは逆順に適用されることに注意\n",
    "# scale_and_shift = shift(scale) # こういう書き方もある\n",
    "\n",
    "y1 = scale_and_shift.forward(z)\n",
    "print(y1)\n",
    "\n",
    "y2 = scale_and_shift.inverse(tf.constant([2., 5., 8.]))\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34a729-a7eb-4022-a48a-7e096b608512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 2.3886688   0.68310845 -0.13735242], shape=(3,), dtype=float32)\n",
      "tf.Tensor([5.7773376 2.366217  0.7252952], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-3.7718077  -1.1522571  -0.92837137], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-4.464955  -1.8454043 -1.6215186], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-4.464955  -1.8454043 -1.6215186], shape=(3,), dtype=float32)\n",
      "tf.Tensor([-4.464955  -1.8454043 -1.6215186], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "normal = tfd.Normal(loc=0., scale=1.)\n",
    "\n",
    "z = normal.sample(3)\n",
    "print(z)\n",
    "\n",
    "scale_and_shift = tfb.Chain([tfb.Shift(1.), tfb.Scale(2.)])\n",
    "\n",
    "x = scale_and_shift.forward(z)\n",
    "print(x)\n",
    "\n",
    "log_prob_z = normal.log_prob(z)\n",
    "print(log_prob_z)\n",
    "\n",
    "log_prob_x = normal.log_prob(z) - scale_and_shift.forward_log_det_jacobian(z, event_ndims=0)\n",
    "print(log_prob_x)\n",
    "# 同値１（forwardとinverseの絶対値が等しいかは、Chainの内容による）\n",
    "print(normal.log_prob(z) + scale_and_shift.inverse_log_det_jacobian(z, event_ndims=0))\n",
    "# 同値２\n",
    "print(normal.log_prob(scale_and_shift.inverse(x)) + scale_and_shift.inverse_log_det_jacobian(x, event_ndims=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b3400f-972d-4a76-9acd-b14238d30e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "normal = tfd.Normal(loc=0., scale=1.)\n",
    "z = normal.sample(3)\n",
    "\n",
    "exp = tfb.Exp()\n",
    "x = exp.forward(z)\n",
    "\n",
    "log_normal = tfd.TransformedDistribution(normal, exp)\n",
    "# ショートカット\n",
    "# log_normal = exp(normal)\n",
    "\n",
    "log_normal.sample() # 内部的には基底分布からサンプリングし、それを対数分布に渡す形になる\n",
    "log_normal.log_prob(x) # 同様にバイジェクターのinverse_log_det_jacobianが適用される"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db60c5c-8ade-4d99-965c-825de8c8b073",
   "metadata": {},
   "source": [
    "# 正規化フロー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffba2bea-6574-4968-9c7c-82b4b10bb676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 0.        ,  0.        ],\n",
       "        [ 0.1824696 , -0.4692711 ],\n",
       "        [-0.54789925, -0.50725967]],\n",
       "\n",
       "       [[ 0.        ,  0.        ],\n",
       "        [ 0.18446818, -0.46734357],\n",
       "        [-0.53440845, -0.4853129 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# 自己回帰ネットワーク\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=2, event_shape=[3], hidden_units=[16, 16], activation='sigmoid')\n",
    "\n",
    "made(tf.random.normal([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13db9b4-7c29-47aa-bd8e-d49a3121acb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# z ~ N(0, I)\n",
    "# x[i] = z[i] * scale(x[0: i-1]) + loc(x[0: i-1]), i = 0,...,D-1\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=2, event_shape=[3], hidden_units=[16, 16], activation='sigmoid')\n",
    "\n",
    "maf_bijector = tfb.MaskedAutoregressiveFlow(shift_and_log_scale_fn=made)\n",
    "\n",
    "def forward(z):\n",
    "    x = tf.zeros_like(z)\n",
    "    for _ in range(D):\n",
    "        shift, log_scale = shift_and_log_scale_fn(x)\n",
    "        x = z * tf.math.exp(log_scale) + shift\n",
    "    return x\n",
    "\n",
    "def inverse(x):\n",
    "    shift, log_scale = shift_and_log_scale_fn(x)\n",
    "    return (x - shift) / tf.math.exp(log_scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7f7ad16-565b-4933-b7b4-280746a42fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfp.distributions._TransformedDistribution(\"masked_autoregressive_flowSampleNormal\", batch_shape=[], event_shape=[3], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# z ~ N(0, I)\n",
    "# x[i] = z[i] * scale(x[0: i-1]) + loc(x[0: i-1]), i = 0,...,D-1\n",
    "\n",
    "made = tfb.AutoregressiveNetwork(\n",
    "    params=2, event_shape=[3], hidden_units=[16, 16], activation='sigmoid')\n",
    "\n",
    "maf_bijector = tfb.MaskedAutoregressiveFlow(shift_and_log_scale_fn=made)\n",
    "\n",
    "normal = tfd.Normal(loc=0, scale=1)\n",
    "maf = tfd.TransformedDistribution( \n",
    "    tfd.Sample(\n",
    "        normal,\n",
    "        sample_shape=[3]),\n",
    "    maf_bijector)\n",
    "print(maf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51121931-9389-458c-b065-b9b1bd313987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# z ~ N(0, I)\n",
    "# x[0: d] = z[0: d]\n",
    "# x[d: D] = z[d: D] * scale(z[0: d]) + loc(z[0: d])\n",
    "\n",
    "shift_and_log_scale_fn = tfb.real_nvp_default_template(\n",
    "    hidden_layers=[32, 32], activation=tf.nn.relu)\n",
    "\n",
    "readnvp_bijector = tfb.RealNVP(\n",
    "    num_masked=2, shift_and_log_scale_fn=shift_and_log_scale_fn)\n",
    "\n",
    "mvn = tfd.MultivariateNormalDiag(loc=[0., 0., 0.])\n",
    "realnvp = tfd.TransformedDistribution(distribution=mvn, bijector=readnvp_bijector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f25d6ab4-3020-4a17-9fca-a774326115a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# z ~ N(0, I)\n",
    "# x[0: d] = z[0: d]\n",
    "# x[d: D] = z[d: D] * scale(z[0: d]) + loc(z[0: d])\n",
    "\n",
    "permute = tfp.bijectors.Permute(permutation=[1, 2, 0])\n",
    "\n",
    "realnvp1 = tfb.RealNVP(fraction_masked=0.5,\n",
    "                shift_and_log_scale_fn=tfb.real_nvp_default_template(hidden_layers=[32, 32]))\n",
    "realnvp2 = tfb.RealNVP(fraction_masked=0.5,\n",
    "                shift_and_log_scale_fn=tfb.real_nvp_default_template(hidden_layers=[32, 32]))\n",
    "realnvp3 = tfb.RealNVP(fraction_masked=0.5,\n",
    "                shift_and_log_scale_fn=tfb.real_nvp_default_template(hidden_layers=[32, 32]))\n",
    "\n",
    "chained_bijector = tfb.Chain([realnvp3, permute, realnvp2, permute, realnvp1])\n",
    "\n",
    "mvn = tfd.MultivariateNormalDiag(loc=[0., 0., 0.])\n",
    "realnvp = tfd.TransformedDistribution(distribution=mvn, bijector=chained_bijector)\n",
    "\n",
    "# history = train_dist_routine(trainable_distribution=realnvp, n_epochs=600, n_disp=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d42997-aa03-49c4-b850-a55897950756",
   "metadata": {},
   "source": [
    "# オートエンコーダー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce74d67-2c57-4a20-809d-23552026c31c",
   "metadata": {},
   "source": [
    "## 普通のオートエンコーダー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e2a8c-5b12-4c3a-b947-9cb3a3581d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Reshape\n",
    "\n",
    "autoencoder = Sequential([\n",
    "    Flatten(input_shape=(28, 28)), # inputをフラット化\n",
    "    Dense(256, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(2, activation='sigmoid'), # いったん次元を圧縮してから戻すのが重要\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(256, activation='sigmoid'),\n",
    "    Dense(784, activation='sigmoid'), # 28 * 28 = 784\n",
    "    Reshape((28, 28)) # inputと同じ次元に戻している\n",
    "])\n",
    "\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rage=0.0005)\n",
    "autoencoder.compile(loss='mse', optimizer=opt)\n",
    "autoencoder.fit(x_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caddb105-e6b3-4c2c-9471-5c5f448b8659",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### エンコーダーとデコーダーを分けると便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99860130-1932-4c00-8e91-aa74f87ff02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Reshape\n",
    "\n",
    "encoder = Sequential([\n",
    "    Flatten(input_shape=(28, 28))\n",
    "    Dense(256, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(2,)),\n",
    "    Dense(256, activation='sigmoid'),\n",
    "    Dense(784, activation='sigmoid')\n",
    "    Reshape((28, 28))\n",
    "])\n",
    "\n",
    "autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='sgd')\n",
    "autoencoder.fit(x_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026133c7-23ba-42f4-a8da-c6f0e3986eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test: (1, 28, 28)\n",
    "reconstruction = autoencoder(x_test) # (1, 28, 28)\n",
    "\n",
    "x_encoded = encoder(x_test) # (1, 2)\n",
    "\n",
    "z = tf.random.normal([1, 2])\n",
    "z_decoded = decoder(z) # (1, 28, 28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294d4c7-4876-4223-ba3c-39ccfdd5993e",
   "metadata": {},
   "source": [
    "## 変分オートエンコーダー（VAE）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b09c03e-18ff-4130-beb2-0e4f2efce4b2",
   "metadata": {},
   "source": [
    "### KLダイバージェンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e1a3f59-3205-4a19-81a4-1e7252da27f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8068528, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8604456, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# 完全一致のとき0\n",
    "distribution_q = tfd.Normal(loc=0., scale=1.)\n",
    "distribution_p = tfd.Normal(loc=0., scale=1.)\n",
    "kl = tfd.kl_divergence(distribution_q, distribution_p) # D_{KL}[q || p]\n",
    "print(kl)\n",
    "\n",
    "# 分布の差が大きいほど大きくなる。最大は無限大。\n",
    "distribution_q = tfd.Normal(loc=0., scale=1.)\n",
    "distribution_p = tfd.Normal(loc=0., scale=0.5)\n",
    "kl = tfd.kl_divergence(distribution_q, distribution_p) # D_{KL}[q || p]\n",
    "print(kl)\n",
    "\n",
    "distribution_q = tfd.Normal(loc=0., scale=1.)\n",
    "distribution_p = tfd.Normal(loc=1., scale=10.5)\n",
    "kl = tfd.kl_divergence(distribution_q, distribution_p) # D_{KL}[q || p]\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b471e5-5258-4020-b390-3ea6f76ae2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# ターゲット分布は共分散ガウス分布（各次元が相互に関連している可能性がある）\n",
    "scale_tril = tfb.FillScaleTril()([-0.5, 1.25, 1.])\n",
    "p = tfd.MultivariateNormalTril(loc=0., scale_tril=scale_tril)\n",
    "\n",
    "# 近似分布は対角ガウス分布（各次元が独立している）\n",
    "q = tfd.MultivariateNormalDiag(\n",
    "    loc = tf.Variable(tf.random.normal([2])),\n",
    "    scale_diag = tfp.util.TransformedVariable(tf.random.uniform([2]))\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def loss_and_grads(q_dist):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = tfd.kl_divergence(q_dist, p) # KLダイバージェンスを損失とする\n",
    "    return loss, tape.gradient(loss, q_dist.trainable_variables)\n",
    "\n",
    "# 分布qが分布pに近づくように学習する\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "for i in range(num_train_steps):\n",
    "    loss, grads = loss_and_grads(q)\n",
    "    opt.apply_gradients(zip(grads, q.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f02e577a-af61-4320-ab94-e26421560a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, Conv2DTranspose\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "latent_size = 2\n",
    "event_shape = (28, 28, 1)\n",
    "\n",
    "encoder = Sequential([\n",
    "    Conv2D(8, (5, 5), strides=2, activation='tanh', input_shape=event_shape),\n",
    "    Conv2D(8, (5, 5), strides=2, activation='tanh'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='tanh'),\n",
    "    Dense(2 * latent_size),\n",
    "    tfpl.DistributionLambda(lambda t: tfd.MultivariateNormalDiag(\n",
    "        loc=t[..., :latent_size], scale_diag=tf.math.exp(t[..., latent_size:])\n",
    "    ))\n",
    "], name = 'encoder')\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='tanh', input_shape=(latent_size,)),\n",
    "    Dense(128, activation='tanh'),\n",
    "    Reshape((4, 4, 8)),\n",
    "    Conv2DTranspose(8, (5, 5), strides=2, output_padding=1, activation='tanh'),\n",
    "    Conv2DTranspose(8, (5, 5), strides=2, output_padding=1, activation='tanh'),\n",
    "    Conv2D(1, (3, 3), padding='SAME'),\n",
    "    Flatten(),\n",
    "    tfpl.IndependentBernoulli(event_shape)\n",
    "], name = 'decoder')\n",
    "\n",
    "prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_size))\n",
    "\n",
    "def loss_fn(x_true, approx_posterior, x_pred, prior_dist):\n",
    "    return tf.reduce_mean(tfd.kl_divergence(approx_posterior, prior_dist)\n",
    "                         - x_pred.log_prob(x_true))\n",
    "\n",
    "@tf.function\n",
    "def get_loss_and_grads(x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        approx_posterior = encoder(x)\n",
    "        approx_posterior_sample = approx_posterior.sample()\n",
    "        x_pred = decoder(approx_posterior_sample)\n",
    "        current_loss = loss_fun(x, approx_posterior, x_pred, prior)\n",
    "    grads = tape.gradient(current_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
    "    return current_loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785ee23-8df7-4cf4-bfec-1c6da72748fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "for epoch in range(num_epochs):\n",
    "    for train_batch in train_data:\n",
    "        loss, grads = get_loss_and_grads(train_batch)\n",
    "        opt.apply_gradients(zip(grads, encoder.trainable_variables + decoder.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb18cf-c869-4ac8-9200-fbe3f7ee2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae(inputs):\n",
    "    approx_posterior = encoder(inputs)\n",
    "    decoding_dist = decoder(approx_posterior.sample())\n",
    "    return decoding_dist.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf65fbd-7d75-4e1a-a4a3-01a060d8b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, Conv2DTranspose\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "latent_size = 4\n",
    "prior = tfd.MultivariateNormalDiag(loc=tf.zeros(latent_size))\n",
    "\n",
    "encoder = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(12,)),\n",
    "    Dense(tfpl.MultivariateNormalTriL.params_size(latent_size)),\n",
    "    tfpl.MultivariateNormalTriL(latent_size),\n",
    "    tfpl.KLDivergenceAddLoss(prior) # パススルーレイヤー。自動的に損失関数を追加する\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(latent_size,)),\n",
    "    Dense(tfpl.IndependentNormal.params_size(12))),\n",
    "    tfpl.IndependentNormal(12)\n",
    "])\n",
    "\n",
    "vae = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "vae.compile(loss=lambda x, pred: -pred.log_prob(x)))\n",
    "vae.fit(train_data, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42dbf8-6e35-4617-b8d5-aa3e43680c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "077abf53-6a7e-4996-b0b8-81417e890d5e",
   "metadata": {},
   "source": [
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc38bc8-41bb-4468-a539-7d2f85572934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector: [2. 3.]\n",
      "Transformed vector: [2.       5.196152]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define the bijector with a specific scaling\n",
    "bijector = tfp.bijectors.ScaleMatvecTriL(scale_tril=tf.linalg.diag([1, 3**0.5]))\n",
    "\n",
    "# Apply the bijector to a vector\n",
    "x = tf.constant([2.0, 3.0])\n",
    "y = bijector.forward(x)\n",
    "\n",
    "# Print the transformed vector\n",
    "print(\"Original vector:\", x.numpy())\n",
    "print(\"Transformed vector:\", y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaf782-0f3a-4461-8f00-b332023036e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9e7d9-363e-4684-9869-876a055a6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
